{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Modèles de Markov cachés</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Depuis quelques années, de nombreuses technologies sont capables de comprendre le langage des Hommes, de comprendre le sens de leurs phrases et sont même capables de leur répondre. On peut citer le système Siri d'Apple ou Alexa d'Amazon. De plus, de nombreuses messageries instanées, telle que Messenger par exemple, sont capables de nous proposer notre prochain mot lorqu'on écrit un message.  \n",
    "Mais comment cela est-il possible ?\n",
    "\n",
    "Toutes les applications que l'on vient de citer font partie d'un domaine de l'intelligence artificielle que l'on appelle *traitement du langage naturel* (ou *natural language processing*). Il inclut entre autre la reconnaissance vocale, la synthèse vocale, la génération de texte ou encore l'étiquetage morpho-syntaxique (*Part-of-Speech tagging*). L'une des principales caractéristique du langage est sa temporalité : un mot ne fait sens dans une phrase parce qu'il est entouré d'un contexte. Les chercheurs n'ont pas attendu l'avènement de l'apprentissage profond et des réseaux de neurones avant de s'intéresser à cette problématique, et de construire des modèles permettant à un ordinateur de comprendre le langage des Hommes.\n",
    "\n",
    "Les **modèles de Markov cachés** font partie des tout premiers modèles utilisés en traitement du langage naturel dès les années 1960. Ils généralisent les chaînes de Markov, très bien connues dans le domaine des probabilités, et ouvrent de nouveaux horizons. L'hypothèse markovienne (que l'on définiera) permet de prendre en compte la temporalité, le contexte, en apportant des informations sur l'instant précédent dans la prédiction à l'instant courrant. C'est pourquoi ces modèles semblent adaptés au traitement du langage naturel.  \n",
    "\n",
    "Dans ce notebook, après avoir introduit les notions essentielles des chaînes de Markov, nous présenterons la théorie des modèles de Markov cachés, les trois problèmes fondamentaux ainsi que leurs méthodes de résolution. Enfin, nous construirons un étiqueteur morpho-syntaxique à l'aide d'un modèle de Markov caché.\n",
    "\n",
    "1. [Introduction aux chaînes de Markov](#sec1)\n",
    "2. [Théorie des chaînes de Markov chachées](#sec2)\n",
    "3. [Les trois problèmes fondamentaux](#sec3)\n",
    "4. [Cas d'application : Part-of-Speech tagging](#sec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id=\"sec1\"></a> Introdution aux chaînes de Markov\n",
    "\n",
    "Dans un premier temps, nous allons présenter les principales définitions et proriétés de la théorie des chaînes de Markov. Pour plus de détails, je vous invite à consulter ce [cours](https://personnel.isae-supaero.fr/IMG/pdf/notes_de_cours.pdf) très complet.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b> Notation </b> : On note $(X_n)_{n\\geq0} \\in E^{\\mathbb{N}}$ une suite de variables aléatoires indexée sur $\\mathbb{N}$ et à valeurs dans un ensemble $E$. On la notera plus couramment $(X_n)$ ou encore $X$.</div>\n",
    "\n",
    "## 1.1 Définitions\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Définition 1.1 [Chaîne de Markov]</b> Une suite de variables aléatoires $(X_n)_{n\\geq0}$ à valeurs dans un espace d’état dénombrable (fini ou infini) $E$ est une chaîne de Markov si pour tout $n ≥ 0$ et tout $x_0,...,x_{n+1} \\in E$ on a : $$\\mathbb{P}(X_{n+1} = x_{n+1} | X_n = x_n,...,X_0 = x_0) = P(X_{n+1} = x_{n+1} | X_n = x_n)$$\n",
    "\n",
    "Si par ailleurs $\\mathbb{P}(X_{n+1} =x_{n+1} |X_n =x_n) = \\mathbb{P}(X_1 =x_{n+1} |X_0 = x_n)$, on dit que $(X_n)$ est <i>homogène en temps</i>. </div>\n",
    "\n",
    "  \n",
    "En d'autres termes, une suite de variables aléatoires $(X_n)$ à valeurs dans un espace d’état dénombrable $E$ est donc une chaîne de Markov si conditionnellement au présent, futur et passé sont indépendants. Un exemple trivial de chaîne de Markov est le cas où les $X_i$ sont indépendantes et identiquement distribuées (i.i.d.). \n",
    "\n",
    "<div class=\"alert alert-success\"> Dans tout le notebook, conformément à nos cas d'applications, nous allons considérer des chaînes de Markov dans un espace d'état $E$ <b>dénombrable</b> (fini ou infini) et <b>homogènes en temps.</b></div>\n",
    "\n",
    "Pour une chaîne de Markov homogène en temps, la probabilité $\\mathbb{P}(X_{n+1} = y | X_n = x)$ ne dépend donc pas du temps (ie $n$) : on appelle cette probabilité **probabilité de transition** (de $x$ à $y$) et on la note $$p_{xy} =P(X_{n+1} = y|X_n = x)=P(X_1 = y|X_0 = x)$$ \n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Définition 1.2 [Matrice de transition] </b> L’ensemble des probabilités de transition définit la matrice de transition notée $P$ et définie par : $$P=(p_{xy})_{x,y \\in E}$$</div>\n",
    "\n",
    "Si $E$ est infini, $P$ est alors une \"matrice infinie\".  \n",
    "$P$ est une matrice stochastique, c'est à dire qu'elle vérifie les propriétés suivantes : \n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{rl}\n",
    "        \\forall x,y \\in E, & p_{xy} \\geq 0 \\\\\n",
    "        \\forall x \\in E, & \\sum_{y\\in E} p_{xy} = 1\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Les deux conditions nous permettent d'affirmer que $\\forall x,y \\in E,  p_{xy} \\in [0,1]$. Il s'agit donc bien de probabilités. De plus, la seconde condition nous dit que pour chaque ligne, la somme de ses éléments vaut $1$. Cela veut dire qu'en partant d'un état $x \\in E$ à l'instant $n$, on va aller dans un état de $E$ à l'instant $n+1$ presque sûrement ($\\mathbb{P}(X_1 \\in E | X_0 = x) = 1$ pour tout $x \\in E$).\n",
    "\n",
    "## 1.2 Premiers exemples\n",
    "\n",
    "Donnons quelques exemples classiques de chaînes de Markov homogènes en temps et sur un espace d'état dénombrable : \n",
    "\n",
    "* **Exemple 1** : Chaîne de Markov à 2 états sur $E = \\{0,1\\}$.\n",
    "<img src=\"Images/Markov.png\" width=\"600px\"></img>\n",
    "On a : $p_{0,1} = p_{1,0} = 1 - p_{0,0} = 1 - p_{1,1} = p \\in [0,1]$, et donc la matrice de transition est donnée par $P = \\begin{pmatrix} 1-p & p \\\\ p & 1-p \\end{pmatrix}$ qui est bien stochastique.\n",
    "En d'autres termes, on change d'état avec une probabilité $p$ et on reste dans le même état avec une probabilité $1-p$.  \n",
    "\n",
    "* **Exemple 2** : Marche aléatoire réfléchie sur $E = \\mathbb{N}$ : \n",
    "<img src=\"Images/MarkovN.png\" width=\"600px\"></img>\n",
    "On a : $p_{x,x+1} = 1 - p_{x,x-1} = p$ pour $x>0$ et $p_{0,1} = 1 - p_{0,0} = p$, et donc la matrice de transition est donnée par la \"matrice\" infinie $P = \\begin{pmatrix} 1-p & p & 0 & 0 & ...\\\\ \n",
    "                                    1-p & 0 & p & 0 & ...\\\\\n",
    "                                    0 & 1-p & 0 & p & ...\\\\\n",
    "                                    0 & 0 & 1-p & 0 & ...\\\\\n",
    "                                    ... & ... & ...& ... & ...\\end{pmatrix}$ \n",
    "qui est stochastique. Autrement dit, dans tous les cas, on va à droite avec une probabilité $p$. En revanche, si on est en $x>0$, on va à gauche avec une probabilité $1-p$ et si on est en $x=0$, on reste en $0$ avec une probabilité $1-p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marche_aleatoire_N(p,n_max = 100):\n",
    "    \"\"\"Retourne une réalisation de la marche aléatoire réfléchie sur N entre 0 et n_max\n",
    "    0 <= p <= 1\n",
    "    n_max : entier naturel\"\"\"\n",
    "    steps = np.random.choice([-1,1],replace=True,size = n_max,p=[1-p,p])\n",
    "    print(steps)\n",
    "    marche = np.zeros(n_max+1)\n",
    "    for n in range(1,n_max+1):\n",
    "        if marche[n-1] == 0:\n",
    "            marche[n] = (1 if steps[n-1] == 1 else 0)\n",
    "        else:\n",
    "            marche[n] = marche[n-1] + steps[n-1]\n",
    "    return marche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1]\n",
      "[-1 -1 -1  1  1]\n",
      "[ 1 -1  1 -1  1]\n",
      "[ 1 -1 -1  1  1]\n",
      "[1 1 1 1 1]\n",
      "[ 1  1 -1  1  1]\n",
      "[ 1  1  1  1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x76f06ec105c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = np.arange(.1,1,.1)\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "for p in probas:\n",
    "    marche = marche_aleatoire_N(p,5)\n",
    "    ax.plot(marche,label=\"p = \" + str(np.round(p,1)))\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"n\")\n",
    "ax.set_ylabel(\"position dans N\")\n",
    "ax.set_title(\"Réalisations d'une marche aléatoire réfléchie sur N\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Exemple fil rouge** : Chaîne de Markov à 3 états : \n",
    "<img src=\"Images/FilRouge.png\" width=\"600px\"></img>\n",
    "Considérons la chaîne de Markov représentée par ce graphe d'état. Pour $n\\geq0$, on pose $X_n$ le temps qu'il fait le jour $n$, de telle sorte que la météo au jour $n$ ne dépend que de la météo au jour $n-1$. $(X_n)$ est donc bien une chaîne de Markov et elle peut prendre 3 valeurs : *sunshine* (état $0$), *rain* (état $1$) et *snow* (état $2$).  \n",
    "La matrice de transition est donnée par $P = \\begin{pmatrix} 0.5 & 0.3 & 0.2\\\\ \n",
    "                                    0.45 & 0.45 & 0.1 \\\\\n",
    "                                    0.4 & 0.3 & 0.3 \\end{pmatrix}$ \n",
    "qui est stochastique. \n",
    "Par exemple, s'il pleut lundi, il y a 45% de chance qu'il fasse beau mardi et 10% de chance qu'il neige mardi.\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Convention </b> : Pour toutes les parties informatiques, nous allons utiliser des numpy arrays pour manipuler les différentes matrices et les vecteurs. L'indexation nécessite l'utilisation d'entiers et non d'états tels que \"sunshine\" par exemple.\n",
    "\n",
    "C'est pourquoi nous allons associer un entier à chaque état $x \\in E$. Nous allons stocker les correspondances dans un dictionnaire. Dans l'exemple fil rouge, on a : <i>sunshine : 0</i>, <i>rain : 1</i> et <i>snow : 2</i></div>\n",
    "\n",
    "Démarrons l'implémentation de notre exemple fil rouge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition de l'espace d'états\n",
    "etats = {\"sunshine\" : 0, \"rain\" : 1, \"snow\" : 2}\n",
    "inv_etats = dict((n,k) for k, n in etats.items())\n",
    "liste_etats = list(etats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de transition :\n",
      "          sunshine  rain snow\n",
      "sunshine      0.5   0.3  0.2\n",
      "rain         0.45  0.45  0.1\n",
      "snow          0.4   0.3  0.3\n"
     ]
    }
   ],
   "source": [
    "#Définition de la matrice de transition\n",
    "df = pd.DataFrame(columns=liste_etats, index=liste_etats)\n",
    "df.loc[liste_etats[0]] = [.5,.3,.2]\n",
    "df.loc[liste_etats[1]] = [.45,.45,.1]\n",
    "df.loc[liste_etats[2]] = [.4,.3,.3]\n",
    "print(\"Matrice de transition :\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5  0.3  0.2 ]\n",
      " [0.45 0.45 0.1 ]\n",
      " [0.4  0.3  0.3 ]]\n",
      "P est stochastique\n"
     ]
    }
   ],
   "source": [
    "P = df.values.astype('float')\n",
    "n_etat = P.shape[0]\n",
    "print(P)\n",
    "#Vérification des conditions d'une matrice stochastique\n",
    "sum_per_row = np.sum(P,axis = 1)\n",
    "is_positive = P>=0\n",
    "if (np.sum(is_positive) == n_etat**2) and (np.sum(sum_per_row == n_etat*[1]) == n_etat):\n",
    "    print(\"P est stochastique\")\n",
    "else:\n",
    "    print(\"P n'est pas stochastique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de réalisation de la chaîne de Markov de l'exemple fil rouge : \n",
      " \n",
      "1 : ['sunshine', 'snow', 'snow', 'snow', 'sunshine', 'rain']\n",
      "2 : ['sunshine', 'rain', 'sunshine', 'sunshine', 'rain', 'snow']\n",
      "3 : ['sunshine', 'rain', 'snow', 'snow', 'snow', 'snow']\n",
      "4 : ['sunshine', 'snow', 'rain', 'sunshine', 'sunshine', 'snow']\n",
      "5 : ['sunshine', 'rain', 'snow', 'sunshine', 'rain', 'sunshine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2502/3019011315.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  X_n[j+1] = np.random.choice([0,1,2],size=1,p=list(P[X_n[j]]))\n"
     ]
    }
   ],
   "source": [
    "def markov_chain(n_max):\n",
    "    \"\"\"Retourne une réalisation entre 0 et n_max de l'exemple fil rouge en partant de 0 à l'instant 0\n",
    "    n_max : entier naturel\"\"\"\n",
    "    X_n = np.zeros(n_max+1,dtype=int)\n",
    "    for j in range(n_max):\n",
    "        X_n[j+1] = np.random.choice([0,1,2],size=1,p=list(P[X_n[j]]))\n",
    "    return X_n\n",
    "\n",
    "print(\"Exemples de réalisation de la chaîne de Markov de l'exemple fil rouge : \\n \")\n",
    "for i in range(5):\n",
    "    X_n = markov_chain(5)\n",
    "    print(\"{} : {}\".format(i+1,[inv_etats[x] for x in X_n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Loi d'une chaîne de Markov\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Définition 1.3 [Loi d’un processus] </b> La loi d’une suite de variables aléatoires $(X_n)_{n\\geq0}$ est la donnée de $\\mathbb{P}(X_0 = x_0,...,X_n = x_n)$ pour tout $n \\geq 0$ et tout $x_0,...,x_n \\in E$.</div>\n",
    "\n",
    "<div class=\"alert alert-info\"> <b> Notation </b> : Pour simplifier à partir de maintenant, pour tout $n\\geq0$ on note $X_0^n = (X_k)_{k \\in [\\![0,n]\\!]}$ la chaîne tuée à l’instant $n$ et $x_0^n = (x_k)_{k \\in [\\![0,n]\\!]}$ une séquence d'états entre les instants $0$ et $n$.</div>\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Théorème 1.1 </b> : Si $X$ est une chaîne de Markov de matrice de transition $P$, alors pour tout $n\\geq0$ et $x_0^n \\in E^{n+1}$, on a : $$\\mathbb{P}(X_0^n = x_0^n) = \\mathbb{P}(X_0 = x_0)\\prod_{i=1}^n p_{x_{i−1}x_i}.$$</div>\n",
    "\n",
    "Pour calculer la loi de la chaîne de Markov, nous avons donc besoin de conditions initiales $\\mathbb{P}(X_0 = 0)$, $\\mathbb{P}(X_0 = 1)$ et $\\mathbb{P}(X_0 = 2)$. Pour l'instant, dans notre exemple fil rouge on ne les connaît pas. On va donc supposer que l'on part de $0$ de telle sorte que $\\mathbb{P}(X_0 = 0) = 1$, et on va calculer la probabilité d'une certaine réalisation $x_0,...,x_n \\in E$ avec la formule ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2]\n",
      "P(X_0^3 = ['sunshine', 'sunshine', 'rain', 'snow']) = 0.015\n"
     ]
    }
   ],
   "source": [
    "#Sachant que l'on part de 0, calcul de la probabilité d'une réalisation\n",
    "n = 3\n",
    "realisation = np.random.randint(0,3,n+1)\n",
    "print(realisation)\n",
    "realisation[0] = 0 #X0 = 0\n",
    "realisation_etat = [inv_etats[n] for n in realisation]\n",
    "proba = 1\n",
    "for i in range(1,n+1):\n",
    "    proba *= P[realisation[i-1],realisation[i]]\n",
    "print(\"P(X_0^{} = {}) = {}\" .format(n, realisation_etat,proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice $P$ ne caractérise pas pleinement la loi de $X$ : il faut une condition initiale $(\\mathbb{P}(X_0 = x_0))_{x_0 \\in E}$. \n",
    "\n",
    "<div class=\"alert alert-info\"> <b> Notation </b> : À partir de maintenant, on notera $\\pi_0$ la condition initiale, avec $\\pi_0 = (\\pi_0(x))_{x \\in E}$ et $\\pi_0(x) = \\mathbb{P}(X_0 = x)$. \n",
    "    \n",
    "On note également $\\pi_n$ la loi de $X_n$, i.e. $\\pi_n = (\\pi_n(x))_{x \\in E}$ avec $\\pi_n(x) = \\mathbb{P}(X_n = x)$.\n",
    "    \n",
    "Pour tout $n\\geq0$, $\\pi_n$ est donc un vecteur colonne de $[0,1]^{E}$ contenant les probabilités $\\mathbb{P}(X_n = x)$ pour tout $x\\in E$.</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Théorème 1.2 </b> : La suite des lois $(\\pi_n)_{n \\geq 0}$ vérifie le système dynamique linéaire déterministe suivant : $$\\forall n \\geq 0, \\ \\pi^T_{n+1} = \\pi^T_n P$$\n",
    "En particulier, $\\forall n \\geq 0, \\ \\pi_n^T = \\pi_0^T P^n$.</div>\n",
    "\n",
    "La loi de $(X_n)$ est alors pleinement définit par $P$ et $\\pi_0$. On peut donc désigner une chaîne de Markov homogène en temps par le couple $(\\pi_0,P)$.\n",
    "\n",
    "Démonstration du théorème 1.2 : Pour $n \\geq 0$ et $x \\in E$ on a : $$\\pi_{n+1}(x) = \\mathbb{P}(X_{n+1} = x) = \\sum_{y\\in E}\\mathbb{P}(X_{n+1} =x|X_n =y)\\mathbb{P}(X_n = y) = \\sum_{y \\in E} p_{yx}\\pi_n(y) = (\\pi_n^T P)_x$$\n",
    "\n",
    "Dans notre exemple fil rouge, nous allons fixer une condition initiale (ie définir $\\pi_0$) et nous serons alors capables de calculer la loi de $X_n$ pour tout $n\\geq0$ avec la dernière formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.5, 0.3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loi initiale\n",
    "pi_0 = np.array([.2, .5, .3])\n",
    "pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loi de X_n pour n dans [0,10] : \n",
      "\n",
      "P(X1 = sunshine) = 0.445000, P(X1 = rain) = 0.375000, P(X1 = snow) = 0.180000\n",
      "P(X2 = sunshine) = 0.463250, P(X2 = rain) = 0.356250, P(X2 = snow) = 0.180500\n",
      "P(X3 = sunshine) = 0.464137, P(X3 = rain) = 0.353437, P(X3 = snow) = 0.182425\n",
      "P(X4 = sunshine) = 0.464086, P(X4 = rain) = 0.353016, P(X4 = snow) = 0.182899\n",
      "P(X5 = sunshine) = 0.464059, P(X5 = rain) = 0.352952, P(X5 = snow) = 0.182988\n",
      "P(X6 = sunshine) = 0.464054, P(X6 = rain) = 0.352943, P(X6 = snow) = 0.183004\n",
      "P(X7 = sunshine) = 0.464052, P(X7 = rain) = 0.352941, P(X7 = snow) = 0.183006\n",
      "P(X8 = sunshine) = 0.464052, P(X8 = rain) = 0.352941, P(X8 = snow) = 0.183006\n",
      "P(X9 = sunshine) = 0.464052, P(X9 = rain) = 0.352941, P(X9 = snow) = 0.183007\n",
      "P(X10 = sunshine) = 0.464052, P(X10 = rain) = 0.352941, P(X10 = snow) = 0.183007\n"
     ]
    }
   ],
   "source": [
    "#Calcul de pi_n\n",
    "N = 10\n",
    "pi = pi_0\n",
    "print(\"Loi de X_n pour n dans [0,{}] : \\n\".format(N))\n",
    "for n in range(N):\n",
    "    pi = pi@P\n",
    "    print(\"P(X%d = sunshine) = %f, P(X%d = rain) = %f, P(X%d = snow) = %f\" % (n+1,pi[0],n+1,pi[1],n+1,pi[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous savons désormais ce qu'est une chaîne de Markov et nous avons énoncé quelques unes de ses propriétés essentielles. Nous avons toutes les bases nécessaires et nous sommmes prêts à s'attaquer à la théorie des chaînes de Markov cachées. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id=\"sec2\"></a> Théorie des modèles de Markov cachés\n",
    "\n",
    "[L'INRIA](http://people.bordeaux.inria.fr/pierre.delmoral/hmm-cappe-moulines-ryden.pdf) présente la théorie des modèles de Markov cachés de manière très mathématique et très formelle (pour les purs matheux) tandis que [Agro ParisTech](http://www2.agroparistech.fr/ufr-info/membres/cornuejols/Teaching/Master-ISI/ISI-10/livre2-v3(ac)-ch-12.pdf), [Kohlschein](https://www.tcs.rwth-aachen.de/lehre/PRICS/WS2006/kohlschein.pdf) et [Stanford](https://web.stanford.edu/~jurafsky/slp3/A.pdf) donnent une version plus accessible et plus orientée algorithmie. Ne s'agissant pas d'un cours de mathématiques poussées, nous allons nous contenter l'approche algorithmie. Mais avant toute chose, définissons tout de même ce qu'est un modèle de Markov caché.\n",
    "\n",
    "Dans cette partie nous allons donner les définitions principales de la théorie des modèles de Markov caché ainsi que ses principales propriétés. Nous allons les illustrer à l'aide de l'exemple fil rouge.\n",
    "\n",
    "## 2.1 Motivations - cas de l'exemple fil rouge\n",
    "\n",
    "Afin de comprendre l'intérêt de la théorie des modèles de Markov cachés, complétons notre exemple fil rouge. Nous avons toujours notre chaîne de Markov $(X_n)$ à valeurs dans un espace d'état $E = \\{sunshine,rain,snow\\}$ et de matrice de transition est $P = \\begin{pmatrix} 0.5 & 0.3 & 0.2\\\\ \n",
    "                                    0.45 & 0.45 & 0.1 \\\\\n",
    "                                    0.4 & 0.3 & 0.3 \\end{pmatrix}$.  \n",
    "                                    \n",
    "Supposons désormais que nous sommes dans une pièce sans fenêtres et sans isolation thermique (oui ce n'est pas très très confortable mais c'est pour la science :) ), de telle sorte qu'on ne peut pas voir le temps qu'il fait, mais qu'on peut savoir s'il fait chaud ou froid dehors. Le temps nous est donc caché, invisible, mais chaque jour nous avons accès à une observation, la température, nous permettant d'avoir un indice sur la météo.  \n",
    "$(X_n)$ devient donc une **suite cachée** et chaque jour la température est une **observation**. Nous faisons l'hypothèse que l'observation effectuée le jour $n$ ne dépend uniquement de la météo ce jour-là.\n",
    "\n",
    "Supposons alors que l'on a les probabilités suivantes : \n",
    "* $\\mathbb{P}(cold|sunshine) = 0.3$ et $\\mathbb{P}(hot|sunshine) = 0.7$ \n",
    "* $\\mathbb{P}(cold|rain) = 0.8$ et $\\mathbb{P}(hot|rain) = 0.2$ \n",
    "* $\\mathbb{P}(cold|snow) = 1$ et $\\mathbb{P}(hot|snow) = 0$   \n",
    "\n",
    "Notre graphe d'état devient donc :\n",
    "\n",
    "<img src=\"Images/HiddenFilRouge.png\" width=\"600px\"></img>\n",
    "\n",
    "Par exemple, s'il pleut lundi, il y a 80% de chances qu'il fasse froid lundi et 20% de chances qu'il fasse chaud.  \n",
    "\n",
    "Nous venons de convertir notre chaîne de Markov fil rouge en un **modèle de Markov caché**, avec une suite cachée à laquelle nous n'avons pas accès (la météo) et une suite d'observations (la température) à laquelle nous avons accès. Formalisons cette idée.\n",
    "\n",
    "## 2.2 Définitions\n",
    "\n",
    "Le modèle de Markov caché généralise le modèle de Markov observable car il produit une séquence en utilisant deux suites de variables aléatoires : l’une cachée et l’autre observable.\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Définition 2.1 [Chaîne de Markov cachée]</b> Un modèle de Markov caché est la donnée de deux suites de variables aléatoires : \n",
    "<li>la suite cachée, $(X_n)_{n\\geq0}$, qui est une chaîne de Markov \"classique\" homogène en temps et à valeurs dans un espace d'état dénombrable $E$  </li>\n",
    "<li>la suite des observations, $(O_n)_{n\\geq0}$, qui est une suite de variables aléatoires et à valeurs dans un ensemble dénombrable $\\mathcal{V}$ appelé <i>vocabulaire</i>.</li>\n",
    "\n",
    "Pour tout $n\\geq0$, ces deux suites vérifient la relation : $$\\forall v_0,...,v_n \\in \\mathcal{V}, \\forall x_0,...,x_n \\in E, , \\mathbb{P}(O_n = v_n | X_0^n = x_0^n, O_0^{n-1} = v_0^{n-1}) = \\mathbb{P}(O_n = v_n | X_n = x_n)$$\n",
    "    \n",
    "Si par ailleurs $\\forall n\\geq0, \\forall v \\in \\mathcal{V}, \\forall x \\in E, \\mathbb{P}(O_n = v | X_n = x) = \\mathbb{P}(O_0 = v | X_0 = x)$, le modèle est dit <i>stationnaire</i>.\n",
    "</div>\n",
    "\n",
    "Autrement dit, pour un modèle de Markov caché stationnaire, pour $x\\in E$ et $v \\in \\mathcal{V}$, la probabilité $\\mathbb{P}(O_n = v | X_n = x)$ ne dépend pas du temps : on appelle cette probabilité **probabilité d'émission** (de $x$ à $v$) et on la note $$b_{xv} = \\mathbb{P}(O_n = v|X_n = x) = \\mathbb{P}(O_0 = v|X_0 = x)$$ \n",
    "\n",
    "<div class=\"alert alert-success\"> À partir de maintenant et conformément à nos cas d'applications, nous allons considérer des modèles de Markov cachés dans un espace d'état $E$ <b>fini</b> (de cardinal $N \\geq1$), <b>homogènes en temps</b>, avec un <b>vocabulaire fini</b> (de cardinal $|\\mathcal{V}|$) et <b>stationnaires</b>.</div>\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Définition 2.2 [Matrice d'émission]</b> L’ensemble des probabilités d'émission définit la matrice d'émission notée $B$ et définie par : $$B=(b_{xv})_{x \\in E, v\\in\\mathcal{V}}$$ </div>\n",
    "De la même manière que la matrice de transition de la chaîne de Markov, la matrice d'émission est une matrice stochastique, c'est à dire qu'elle vérifie : \n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{rl}\n",
    "        \\forall x \\in E, \\forall v \\in \\mathcal{V}, & b_{xv} \\geq 0 \\\\\n",
    "        \\forall x \\in E, & \\sum_{v\\in \\mathcal{V}} b_{xv} = 1\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Convention </b> Pour la même raison que pour les états, nous allons associer un entier à chaque élément du vocabulaire pour l'indexation de la matrice d'émission : <i>cold : 0</i> et <i>hot : 1</i>.</div>\n",
    "\n",
    "\n",
    "Implémentons la matrice d'émission de notre chaîne de Markov cachée : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition du vocabulaire\n",
    "vocabulaire = {'Cold':0, 'Hot':1}\n",
    "inv_vocabulaire = dict((n,k) for k, n in vocabulaire.items())\n",
    "list_vocabulaire = list(vocabulaire.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Matrice d'émission :\n",
      "          Cold  Hot\n",
      "sunshine  0.3  0.7\n",
      "rain      0.8  0.2\n",
      "snow        1    0\n"
     ]
    }
   ],
   "source": [
    "#Définition de la matrice d'émission\n",
    "b_df = pd.DataFrame(columns=list_vocabulaire, index=liste_etats)\n",
    "b_df.loc[liste_etats[0]] = [.3,.7]\n",
    "b_df.loc[liste_etats[1]] = [0.8,0.2]\n",
    "b_df.loc[liste_etats[2]] = [1,0]\n",
    "B = b_df.values.astype(\"float\")\n",
    "print(\"\\n Matrice d'émission :\\n\",b_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour générer une séquence d'observations à partir d'un modèle de Markov caché, il faut suivre la procédure suivante : \n",
    "* 1 - tirer l'état initial $X_0$ selon la loi initiale $\\pi_0$\n",
    "* 2 - tirer l'observation initiale $O_0$ suivant les probabilités d'émission correspondantes à $X_0$\n",
    "* 3 - à partir de l'état $X_i$ à l'instant $i$, aller à l'état suivant $X_{i+1}$ suivant les probabilités de transition\n",
    "* 4 - tirer l'observation $O_{i+1}$ à l'instant $i+1$ suivant les probabilités d'émission\n",
    "* 5 - retourner à l'étape 3 et recommencer jusqu'à l'arrêt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_markov_model(n,pi_0,P,B): \n",
    "    \"\"\"Génération d'une séquence de (n+1) états et de (n+1) observations entre les instants 0 et n\n",
    "    n : entier naturel\n",
    "    pi_0 : distribution initiale de la suite cachée\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\n",
    "    \"\"\"\n",
    "    X_n = np.zeros(n+1,dtype=int)\n",
    "    O_n = np.zeros(n+1,dtype=int)\n",
    "    E = list(range(P.shape[0])) #Espace d'états\n",
    "    V = list(range(B.shape[1])) #Vocabulaire\n",
    "    \n",
    "    #initialisation\n",
    "    X_n[0] = np.random.choice(E,size=1,p=pi_0)\n",
    "    O_n[0] = np.random.choice(V,size=1,p = list(B[X_n[0]]))\n",
    "    \n",
    "    #récurrence\n",
    "    for i in range(n):\n",
    "        X_n[i+1] = np.random.choice(E,size=1,p = list(P[X_n[i]]))\n",
    "        O_n[i+1] = np.random.choice(V,size=1,p = list(B[X_n[i+1]]))\n",
    "    return X_n,O_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de réalisation du modèle de Markov caché : \n",
      "\n",
      "X_0 = snow, O_0 = Cold\n",
      "X_1 = snow, O_1 = Cold\n",
      "X_2 = snow, O_2 = Cold\n",
      "X_3 = rain, O_3 = Cold\n",
      "X_4 = rain, O_4 = Cold\n",
      "X_5 = rain, O_5 = Cold\n"
     ]
    }
   ],
   "source": [
    "X,O = hidden_markov_model(5,pi_0,P,B)\n",
    "print(\"Exemple de réalisation du modèle de Markov caché : \\n\")\n",
    "for i in range(len(X)):\n",
    "    print(\"X_\" + str(i) + \" = \" + inv_etats[X[i]] +\", O_\" + str(i) + \" = \"+ inv_vocabulaire[O[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Loi du processus $(X,O)$\n",
    "\n",
    "De la même manière que pour les chaînes de Markov classiques, intéressons nous à la loi de la suite $(X_n,O_n)_{n\\geq0}$.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Théorème 2.1 </b> : Pour tout $n \\geq 0$, tout $x_0, ..., x_n \\in E$ et pour tout $v_0, ..., v_n \\in \\mathcal{V}$, on a :\n",
    "$$\\mathbb{P}(X_0^n = x_0^n, O_0^n = v_0^n) = \\pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i}$$\n",
    "</div>\n",
    "\n",
    "Démonstration du théorème 2.1 : Soit $x_0, ..., x_n \\in E$ et $v_0, ..., v_n \\in \\mathcal{V}$. On a : \n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(X_0^n = x_0^n, O_0^n = v_0^n) &= \\mathbb{P}(O_0^n = v_0^n | X_0^n = x_0^n) \\mathbb{P}(X_0^n = x_0^n) \\\\\n",
    "&= \\mathbb{P}(X_0^n = x_0^n) \\mathbb{P}(O_0 = v_0 | X_0^n = x_0^n) \\prod_{i=1}^n \\mathbb{P}(O_i = v_i | X_0^n = x_0^n, O_0^{i-1} = v_0^{i-1})\\\\\n",
    "&= \\mathbb{P}(X_0^n = x_0^n) \\prod_{i=0}^n \\mathbb{P}(O_i = v_i | X_i = x_i) \\ \\ \\ \\text{par la propriété de Markov sur les observations} \\\\\n",
    "&= \\pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i} \n",
    "\\end{align}\n",
    "\n",
    "Ce théorème nous permet d'affirmer que la loi du processus $(X,O)$ est donc entièrement déterminé par $\\pi_0$, $P$ et $B$. De la même manière que pour les chaînes de Markov classiques, on peut désigner une chaîne de Makov caché par le triplet $(\\pi_0,P,B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "realisation = np.random.randint(0,3,n+1)\n",
    "sequence_obs = np.random.randint(0,2,n+1)\n",
    "realisation_etat = [inv_etats[n] for n in realisation]\n",
    "observations_etat = [inv_vocabulaire[n] for n in sequence_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_0^2 = ['sunshine', 'rain', 'sunshine'],O_0^2 = ['Hot', 'Cold', 'Hot']) = 0.010584\n"
     ]
    }
   ],
   "source": [
    "#Calcul de la probabilité d'une réalisation de (X,O)\n",
    "proba = pi_0[realisation[0]] * B[realisation[0],sequence_obs[0]]\n",
    "for i in range(1,n+1):\n",
    "    proba *= P[realisation[i-1],realisation[i]] * B[realisation[i],sequence_obs[i]]\n",
    "print(\"P(X_0^{} = {},O_0^{} = {}) = {}\".format(n, realisation_etat,n,observations_etat,proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id=\"sec3\"></a> Les trois problèmes fondamentaux\n",
    "\n",
    "Lorsqu'un data scientist décide d'utiliser un modèle de Markov caché pour représenter un phénomène, par exemple en traitement du langage naturel, un gros problème se pose à lui : la suite d'états n'est pas accessible, il ne possède que la suite d'obervations. Deux types de situations sont alors possibles : \n",
    "* soit les paramètres $(\\pi_0,P,B)$ sont connus et on peut alors faire des calculs sous ce modèle\n",
    "* soit ils ne le sont pas, auquel cas on voudrait les déterminer à partir d'observations, comme le ferait un réseau de neurones\n",
    "\n",
    "<div class=\"alert alert-info\"> <b> Notation </b> : Dans toute cette partie, pour un modèle de Markov caché $\\lambda = (\\pi_0,P,B)$ et une séquence d'observations $v_0^n \\in \\mathcal{V}^{n+1}$, on note par $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$ la probabilité que le modèle caché $\\lambda$ ait émis la séquence $v_0^n$.</div>\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Convention </b> : En adéquation avec les correspondances <i>entier/état</i> et <i>entier/mot</i> que nous avons créées, les algorithmes de cette partie ne traiteront uniquement que des entiers (en d'autres termes : $E = [\\![0,N-1]\\!]$ et $\\mathcal{V} = [\\![0,|\\mathcal{V}| - 1]\\!]$) La conversion vers les états et les mots se feront grâce aux dictionnaires de correspondances.</div>\n",
    "\n",
    "Étant donnée une séquence d'obervations $v_0^n \\in \\mathcal{V}^{n+1}$, il existe trois problèmes fondamentaux qui méritent notre attention et qui doivent être résolus : \n",
    "\n",
    "* **Problème 1 (calcul de probabilité)** : étant donné un modèle $\\lambda = (\\pi_0,P,B)$, calculer efficacement la probabilité d'observer cette séquence\n",
    "* **Problème 2 (le déchiffrage)** : étant donné un modèle $\\lambda = (\\pi_0,P,B)$, déterminer la séquence d'états $x_0^n \\in E^{n+1}$ correspondante la plus probable\n",
    "* **Problème 3 (l'apprentissage)** : déterminer les paramètres du modèle $\\lambda^* = (\\pi_0^*,P^*,B^*)$ qui maximisent $\\mathbb{P}_{\\lambda}(O_0^n = v_0^n)$\n",
    "\n",
    "Nous considérons toujours le modèle de Markov caché de notre exemple fil rouge dont les paramètres $\\lambda = (\\pi_0,P,B)$ sont donnés par :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètres de notre exemple fil rouge : \n",
      "\n",
      " - Conditions initiales : \n",
      "pi_0 = [0.2 0.5 0.3]\n",
      "\n",
      " - Matrice de transition : \n",
      "P = [[0.5  0.3  0.2 ]\n",
      " [0.45 0.45 0.1 ]\n",
      " [0.4  0.3  0.3 ]]\n",
      "\n",
      " - Matrice d'émission : \n",
      "B = [[0.3 0.7]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Paramètres de notre exemple fil rouge : \")\n",
    "print(\"\\n - Conditions initiales : \")\n",
    "print(\"pi_0 = \" + str(pi_0))\n",
    "print(\"\\n - Matrice de transition : \")\n",
    "print(\"P = \" + str(P))\n",
    "print(\"\\n - Matrice d'émission : \")\n",
    "print(\"B = \" + str(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons présenter dans cette partie les méthodes de résolution de ces trois problèmes. [Rabiner](https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf) s'intéresse particulièrement à cette problématique.\n",
    "\n",
    "## 3.1 Problème 1 : calcul de probabilité\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> But </b> : Étant donné un modèle caché $\\lambda = (\\pi_0,P,B)$ et une séquence d'observations $v_0^n \\in \\mathcal{V}^{n+1}$, calculer $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$.</div>\n",
    "\n",
    "Dans le cas de notre exemple fil rouge, on veut par exemple déterminer la probabilité d'observer la séquence *hot-hot-cold-hot-cold*.\n",
    "\n",
    "### 3.1.1 Première approche théorique\n",
    "\n",
    "Théoriquement, ce problème est très simple à résoudre : connaissant le modèle $\\lambda = (\\pi_0,P,B)$, le théorème 2.1 nous donne la loi couplée $(X,O)$ et nous sommes capable de calculer la loi de la suite $(O_n)$ via la formule :$$\\mathbb{P}_\\lambda(O_0^n = v_0^n) = \\sum_{x_0^n \\in E^{n+1}} \\mathbb{P}_\\lambda(X_0^n = x_0^n, O_0^n = v_0^n) = \\sum_{x_0^n \\in E^{n+1}}\\pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i}$$\n",
    "Cependant, nous aimerions pouvoir calculer cette probabilité informatiquement. Faisons alors un peu de dénombrement.  \n",
    "Si $E$ est fini de cardinal $N>0$, alors $Card(E^{n+1}) = N^{n+1}$. La probabilité voulue est donc une somme de $N^{n+1}$ termes. Il y a donc $N^{n+1} - 1$ sommes à effectuer. De plus, chaque terme est composé de $2n+1$ produits.  \n",
    "Pour calculer cette probabilité, il faut donc réaliser $(2n+1)N^{n+1}$ produits et $N^{n+1} - 1$ sommes, soit $2(n+1)N^{n+1} - 1 \\approx 2nN^{n+1}$ opérations élémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309226512439206798621876677859372763621264513200600 opérations soit plus de 10^50.\n"
     ]
    }
   ],
   "source": [
    "#Calcul de la complexité dans l'exemple fil rouge\n",
    "N = 3\n",
    "n = 100\n",
    "n_op = 2*n*N**(n+1)\n",
    "print(\"{} opérations soit plus de 10^{}.\".format(n_op,int(np.log10(np.float(n_op)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre exemple fil rouge, l'espace d'état est composé de seulement 3 éléments. Pour calculer la probabilité de réalisation d'une séquence de $n = 100$ observations, il faut plus de $10^{50}$ opérations élémentaires. Je vous laisse imaginer le nombre d'opérations élémentaires qu'il faudrait si l'espace d'état était bien plus grand, comme c'est le cas dans des applications plus courantes.\n",
    "\n",
    "Excepté pour des cas simplissimes, il est donc impossible de calculer la probabilité voulue informatiquement avec cette méthode. Il est donc nécessaire de développer une autre méthode pour calculer $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$.\n",
    "\n",
    "### 3.1.2 L'algorithme du Forward\n",
    "\n",
    "Nous devons trouver un moyen plus efficace de calculer la probabilité $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$. Heureusement, un tel algorithme existe : **l'algorithme du Forward** qui a une complexité en $\\mathcal{O}(nN^2)$. L'astuce ici est de s'intéresser aux coefficients de Forward : \n",
    "\n",
    "<div class=\"alert alert-danger\"><b> Définition 3.1 [Coefficient de forward]</b>$$\\forall i \\in [\\![0,n]\\!], \\forall x \\in E, \\alpha_i(x) = \\mathbb{P}_\\lambda(O_0^{i} = v_0^{i}, X_i = x) $$</div> \n",
    "\n",
    "$\\alpha_i(x)$ représente la probabilité d'observer la séquence tronquée $v_0^{i}$ et que la suite cachée est dans l'état $x$ à l'instant $i$. En d'autres termes, il représente la probabilité d'arriver en $x$ à l'instant $i$ tout en suivant la séquence d'observations.  \n",
    "L'intérêt de ces coefficients est qu'ils vérifient deux relations extrêmement intéressantes.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Proposition 3.1</b> : Les coefficients $\\alpha_i(x)$ vérifient les relations : \n",
    "    \n",
    "$$\\left\\{\n",
    "    \\begin{array}{l}\n",
    "        \\mathbb{P}_\\lambda(O_0^n = v_0^n) = \\sum_{x\\in E} \\alpha_n(x) \\ \\ \\ \\text{(i)}\\\\\n",
    "        \\forall i \\in [\\![0,n-1]\\!], \\forall x \\in E, \\alpha_{i+1}(x) = \\sum_{y\\in E} \\alpha_i(y) p_{yx} b_{xv_{i+1}} \\ \\ \\ \\text{(ii)}\n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "</div> \n",
    "\n",
    "Démonstration de la proposition 3.1 :  \n",
    "(i) On a : $\\mathbb{P}_\\lambda(O_0^n = v_0^n) = \\sum_{x \\in E} \\mathbb{P}_\\lambda(O_0^{n} = v_0^{n}, X_i = x) = \\sum_{x\\in E} \\alpha_n(x)$  \n",
    "(ii) Soit $i \\in [\\![0,n-1]\\!]$ et $x\\in E$. On a \n",
    "\\begin{align}\n",
    "\\alpha_{i+1}(x) &= \\mathbb{P}_{\\lambda}(O_0^{i+1} = v_0^{i+1}, X_{i+1} = x) \\\\\n",
    "&= \\sum_{y\\in E} \\mathbb{P}_{\\lambda}(O_0^{i} = v_0^{i}, X_i = y, O_{i+1} = v_{i+1}, X_{i+1} = x) \\\\\n",
    "&= \\sum_{y\\in E} \\mathbb{P}_{\\lambda}(O_0^{i} = v_0^{i}, X_i = y) \\mathbb{P}_{\\lambda}(X_{i+1} = x | O_0^{i} = v_0^{i}, X_i = y) \\mathbb{P}_{\\lambda}(O_{i+1} = v_{i+1}|X_{i+1} = x, O_0^{i} = v_0^{i}, X_i = y) \\\\\n",
    "&= \\sum_{y\\in E} \\alpha_i(y) \\mathbb{P}_{\\lambda}(X_{i+1} = x | X_i = y) \\mathbb{P}_{\\lambda}(O_{i+1} = v_{i+1}|X_{i+1} = x) \\\\\n",
    "&= \\sum_{y\\in E} \\alpha_i(y) p_{yx} b_{xv_{i+1}}\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"Images/Forward.png\" width=\"600px\"></img>\n",
    "\n",
    "La figure illustre bien la relation de récurrence, et comment on calcul les coefficients à l'instant $i$ en fonction de ceux à l'instant $i-1$. La probabilité d'être en point est précisément égale à $\\alpha_i(x)$. Chaque point à l'instant $i$ découme de tous les points à l'instant $i-1$ car pour émettre le début de l’observation $v_0^{i}$ et aboutir dans l’état $x$ au temps $i$, on doit nécessairement être dans l’un des états $y\\in E$ à l’instant $i-1$.\n",
    "\n",
    "\n",
    "La proposition ci-dessus nous donne une relation de récurrence sur les coefficients ainsi qu'un moyen d'obtenir la probabilité voulue à partir des coefficients à l'instant final. Le principe de l'algorithme est assez simple : on va calculer les coefficient $\\alpha_i(x)$ pour tout état $x$ et à tout instant $i$ en avançant étape par étape afin d'arriver à l'instant $n$, pour finalement faire la somme finale.  \n",
    "Le pseudo-code de l'algorithme du Forward est donné par :\n",
    "\n",
    "<img src=\"Images/PseudoCodeForward.png\" width=\"500px\"></img>\n",
    "    \n",
    "1) Durant la phase d'initialisation, on définit $\\alpha_0(x)$ pour tout $x \\in E$ à l'aide de la formule :  $$\\alpha_0(x) = \\mathbb{P}_\\lambda(O_0 = v_0, X_0 = x) = \\mathbb{P}_\\lambda(O_0 = v_0 | X_0 = x) \\mathbb{P}_\\lambda(X_0 = x) = \\pi_0(x)b_{xv_0}$$\n",
    "2) Ensuite, on utilise la relation de récurrence pour calculer les coefficients à tout instant  \n",
    "3) Finalement, on retourne la probabilité voulue à l'aide de la somme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(obs_seq,pi_0,P,B):\n",
    "    \"\"\"Retourne la probabilité d'observer la séquence obs_seq\n",
    "    obs_seq : liste d'observations\n",
    "    pi_0 : conditions initiales de la suite cachée\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\"\"\"\n",
    "    N = P.shape[0] #Taille de l'espace d'états\n",
    "    n = len(obs_seq) - 1 #Instant final de la séquence\n",
    "    forward = np.zeros((N,n+1))\n",
    "    \n",
    "    #Initialisation\n",
    "    forward[:,0] = pi_0*B[:,obs_seq[0]]\n",
    "    \n",
    "    #Récurrence\n",
    "    for i in range(1,n+1):\n",
    "        for x in range(N):\n",
    "            prod = forward[:,i-1] * P[:,x] * B[x,obs_seq[i]]\n",
    "            forward[x,i] = np.sum(prod)\n",
    "            \n",
    "    #Fin avec la somme à l'instant n\n",
    "    return np.sum(forward[:,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(O_0^5 = ['Cold', 'Hot', 'Hot', 'Hot', 'Cold', 'Cold']) = 0.017521115868\n"
     ]
    }
   ],
   "source": [
    "n_max = 5\n",
    "sequence = np.random.randint(0,2,n_max+1)\n",
    "forward_prob = forward_algorithm(sequence,pi_0,P,B)\n",
    "print(\"P(O_0^{} = {}) = {}\".format(n_max,[inv_vocabulaire[x] for x in sequence],forward_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons sa complexité : \n",
    "* 1) durant l'initialisation, on effectue seulement $N$ produits  \n",
    "* 2) durant la récursion, on effectue $2N$ produits par étapes et $N-1$ sommes, le tout $N$ fois. On effetue cela $n$ fois.  \n",
    "* 3) à la fin, on effectue une fois $N$ sommes  \n",
    "Durant tout l'algorithme, on effectue alors $2N + nN(2N+N-1)$ opérations élémentaires et on retrouve bien une complexité en $\\mathcal{O}(nN^2)$.  \n",
    "Nous sommes désormais capable de calculer la probabilité $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$ efficacement.\n",
    "\n",
    "On peut faire remarquer qu'il existe des variantes équivalentes de cet algorithme qui permettent également de calculer la probabilité voulue. On peut citer l'algorithme du backward ou l'algorithme du forward-backward.\n",
    "\n",
    "## 3.2 Problème 2 : le décryptage\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> But </b> : Étant donné un modèle caché $\\lambda = (\\pi_0,P,B)$ et une séquence d'observations $v_0^n \\in \\mathcal{V}^{n+1}$, déterminer la suite d'états $x_0^n \\in E^{n+1}$ qui maximise $\\mathbb{P}_\\lambda(O_0^n = v_0^n, X_0^n = x_0^n)$. Autrement dit, résoudre : $$\\underset{x_0^n\\in E^{n+1}}{\\text{argmax}} \\ \\mathbb{P}_\\lambda(O_0^n = v_0^n, X_0^n = x_0^n)$$</div>\n",
    "\n",
    "En d'autres termes, on essaie ici de deviner la suite cachée derrière les observations faites.\n",
    "Dans le cas de notre exemple fil rouge, étant donnée une séquence d'observation *hot-hot-cold-hot-cold* par exemple, on veut déterminer la combinaison des météos sur ces 5 jours la plus probable.  \n",
    "\n",
    "Naïvement, la première idée qui nous vient à l'esprit est de calculer $\\mathbb{P}_\\lambda(O_0^n = v_0^n, X_0^n = x_0^n)$ pour toutes les suites d'états $x_0^n \\in E^{n+1}$ et déterminer celle qui maximise la probabilité. Mais cette solution est beaucoup trop coûteuse informatiquement, pour les mêmes raisons que celles évoquées lors du problème 1. Heureusement, il existe ici aussi un algorithme qui permet de déterminer la séquence la plus probable efficacement : **l'algorithme de Viterbi**.  \n",
    "\n",
    "L'astuce de cet algorithme est de considéré les coefficients de Viterbi : \n",
    "\n",
    "<div class=\"alert alert-danger\"><b> Définition 3.2 [Coefficient de Viterbi]</b>$$\\forall i \\in [\\![0,n]\\!], \\forall x \\in E, \\delta_i(x) = \\underset{x_0^{i-1} \\in E^{i}}{\\max} \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_i = x)$$ avec $x_0^{-1}$ la séquence vide (d'où $\\delta_0(x) = \\mathbb{P}_\\lambda(O_0 = v_0, X_0 = x)$).</div> \n",
    "\n",
    "Autrement dit, $\\delta_i(x)$ est la probabilité du meilleur chemin amenant à l’état $x$ à l’instant $i$, en étant guidé par les $i$ premières observations.\n",
    "\n",
    "L'intérêt de ces coefficients est qu'ils vérifient une relation de récurrence qui nous permettra d'avancer dans le temps.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Proposition 3.2</b> : Les coefficients de viterbi $\\delta_i(x)$ vérifient la relation de récurrence : \n",
    "$$\\forall i\\in [\\![0,n-1]\\!], \\forall x\\in E, \\delta_{i+1}(x) = \\underset{y\\in E}{\\max} \\delta_i(y) p_{yx} b_{xv_{i+1}}$$\n",
    "</div> \n",
    "\n",
    "Démontration de la proposition 3.2 :  \n",
    "Soit $i \\in [\\![0,n-1]\\!]$ et $x \\in E$. On a : \n",
    "\\begin{align}\n",
    "\\delta_{i+1}(x) &= \\underset{x_0^{i} \\in E^{i+1}}{\\max} \\mathbb{P}_\\lambda(X_0^{i} = x_0^{i}, O_0^{i+1} = v_0^{i+1}, X_{i+1} = x) \\\\\n",
    "&= \\underset{x_0^{i} \\in E^{i+1}}{\\max} \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = x_i, O_{i+1} = v_{i+1}, X_{i+1} = x)\\\\\n",
    "&= \\underset{x_0^{i} \\in E^{i+1}}{\\max} \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = x_i) \\mathbb{P}_\\lambda(X_{i+1} = x | X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = x_i) \\\\\n",
    "& \\hspace{8cm}\\mathbb{P}_\\lambda(O_{i+1} = v_{i+1} | X_{i+1} = x, X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = x_i) \\\\\n",
    "&= \\underset{x_0^{i} \\in E^{i+1}}{\\max} \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = x_i) \\mathbb{P}_\\lambda(X_{i+1} = x | X_{i} = x_i) \\mathbb{P}_\\lambda(O_{i+1} = v_{i+1} | X_{i+1} = x) \\\\\n",
    "&= \\underset{x_0^{i-1} \\in E^{i}}{\\max} \\underset{y\\in E}{\\max} \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = y)  \\mathbb{P}_\\lambda(X_{i+1} = x | X_{i} = y) \\mathbb{P}_\\lambda(O_{i+1} = v_{i+1} | X_{i+1} = x)\\\\\n",
    "&= \\underset{y\\in E}{\\max} \\underset{x_0^{i-1} \\in E^{i}}{\\max} \\left[ \\mathbb{P}_\\lambda(X_0^{i-1} = x_0^{i-1}, O_0^{i} = v_0^{i}, X_{i} = y)\\right]  \\mathbb{P}_\\lambda(X_{i+1} = x | X_{i} = y) \\mathbb{P}_\\lambda(O_{i+1} = v_{i+1} | X_{i+1} = x)\\\\\n",
    "&= \\underset{y\\in E}{\\max} \\delta_i(y) p_{yx} b_{xv_{i+1}}\n",
    "\\end{align}\n",
    "\n",
    "Le principe de l'algorithme est de garder en mémoire au fil du temps, à l'aide d'un tableau $\\psi$ (qui représente l'état qui maximise le terme de droite de la relation de récurrence), la suite d'états qui donne le meilleur chemin pour arriver en $x \\in E$ à l'instant $i$. Intuitivement, on va calculer les coefficients $\\delta_i(x)$ pour tout état $x$ à tout instant $i$ récursivement, de la même manière que lors de l'algorithme précédent (la *somme* est remplacée par le *maximum*). Une fois arriver à l'instant final $n$, on va utiliser le tableau $\\psi$ que l'on a construit au fur et à mesure afin de remonter via le meilleur chemin.  \n",
    "\n",
    "Le pseudo-code de l'algorithme est donné par :\n",
    "\n",
    "<img src=\"Images/PseudoCodeViterbi.png\" width=\"400px\"></img>\n",
    "\n",
    "<img src=\"Images/Viterbi.png\" width=\"700px\"></img>\n",
    "\n",
    "Cette figure représentente graphiquement ce que fait l'algorithme. Les flèches noires vers la droite représentent le calcul récursif des coefficients de Viterbi pour chaque point. Une fois arrivé à la fin, on remonte en choississant le bon état (flèches bleues en pointillées). Par exemple sur la figure, l'état du meilleur chemin à l'instant $1$ est $H$.  \n",
    "\n",
    "Implémentons l'algorithme de Viterbi : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(obs_seq,pi_0,P,B):\n",
    "    \"\"\"Retourne la séquence cachée la plus probable ainsi que la probabilité correspondante\n",
    "    obs_seq : liste d'observations\n",
    "    pi_0 : conditions initiales de la suite cachée\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\n",
    "    \"\"\"\n",
    "    N = P.shape[0] #Taille de l'espace d'états\n",
    "    n = len(obs_seq) - 1 #Instant final de la séquence\n",
    "    viterbi = np.zeros((N,n+1))\n",
    "    psi = np.zeros((N,n+1),dtype=int)\n",
    "    \n",
    "    #Initialisation\n",
    "    viterbi[:,0] = pi_0 * B[:,obs_seq[0]]\n",
    "    psi[:,0] = -1\n",
    "    \n",
    "    #Récurrence\n",
    "    for i in range(1,n+1):\n",
    "        for x in range(N):\n",
    "            viterbi[x,i] = np.max(viterbi[:,i-1] * P[:,x] * B[x,obs_seq[i]])\n",
    "            psi[x,i] = np.argmax(viterbi[:,i-1] * P[:,x])\n",
    "            \n",
    "    \n",
    "    best_path_prob = np.max(viterbi[:,n])\n",
    "    best_path_pointer = np.argmax(viterbi[:,n])\n",
    "    \n",
    "    best_path = [best_path_pointer]\n",
    "    \n",
    "    #Remonté via le meilleur chemin\n",
    "    for i in range(n,0,-1):\n",
    "        best_path = [psi[best_path[0],i]] + best_path\n",
    "        \n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rain', 'rain', 'sunshine'] est le chemin le plus probable pour les observations ['Hot', 'Cold', 'Hot']\n",
      "La probabilité correspondante est 0.011340000000000001.\n"
     ]
    }
   ],
   "source": [
    "n_max = 2\n",
    "sequence = np.random.randint(0,2,n_max+1)\n",
    "best_path, best_prob = viterbi_algorithm(sequence,pi_0,P,B)\n",
    "print(\"{} est le chemin le plus probable pour les observations {}\".format(\n",
    "    [inv_etats[x] for x in best_path],[inv_vocabulaire[x] for x in sequence]))\n",
    "print(\"La probabilité correspondante est {}.\".format(best_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on peut remarquer que comme pour l'algorithme du Forward, la complexité de cette algorithme est en $\\mathcal{O}(nN^2)$.\n",
    "\n",
    "## 3.3 Problème 3 : l'apprentissage\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> But </b> : Étant donné une séquence d'observations $v_0^n \\in \\mathcal{V}^{n+1}$, les paramètres d’un modèle de Markov caché $\\lambda^* = (\\pi_0^*,P^*,B^*)$ qui maximisent la probabilité $\\mathbb{P}_{\\lambda}(O_0^n = v_0^n)$. Autrement dit, résoudre : $$\\underset{\\pi_0,P,B}{\\text{argmax}} \\ \\mathbb{P}_{\\lambda}(O_0^n = v_0^n)$$</div>\n",
    "\n",
    "### 3.3.1 Intuition\n",
    "\n",
    "Ce problème est, de loin, le plus compliqué des trois à résoudre. Techniquement, nous disposons des outils pour résoudre ce problème analytiquement. En effet, on a déjà prouvé que $$\\mathbb{P}_\\lambda(O_0^n = v_0^n) = \\sum_{x_0^n \\in E^{n+1}}\\pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i}$$ \n",
    "Il s'agit donc ni plus ni moins qu'un problème d'optimisation déterministe sur $\\mathbb{R}^{N+N^2+|\\mathcal{V}|N}$ sous contraintes de stochasticité des différents paramètres. On pourrait alors écrire le Langrangien de la fonction objectif ainsi que les contraintes de Karush-Kuhn-Tucker (KKT) afin de trouver les paramètres optimaux.  \n",
    "Si vous êtes motivés pour faire tout ça avec notre fonction objectif : bon courage ! On pourrait également tenter d'appliquer l'algorithme de descente de gradient par exemple, mais nous allons nous intéresser à un autre algorithme.\n",
    "\n",
    "La résolution analytique de ce problème étant extrêmement compliquée, nous allons développer un algorithme itératif qui à partir d'un état initial, va mettre à jour les paramètres afin d'améliorer l'estimation des paramètres optimaux, c'est à dire qu'à chaque itération, on va calculer de nouveaux paramètres $(\\pi_0,P,B)$ qui vont augmenter la probabilité $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$. Il s'agit de **l'algorithme du Forward-Backward**, ou **l'algorithme de Baum-Welch**. Il ne donne pas de solution exacte du problème, mais permet d'approcher la solution.\n",
    "\n",
    "Intuitivement, à partir du modèle à l'itération $m\\geq0$, on va calculer les paramètres du modèle à l'itération $m+1$ de la manière suivante : \n",
    "\n",
    "$$\\pi^{(m+1)}(x) = \\frac{\\text{nombre de fois où le modèle s’est trouvé dans l’état $x$ en émettant le premier symbole d’une phrase sous $\\lambda_m$}}{\\text{nombre de fois où le modèle a émis le premier symbole d’une phrase sous $\\lambda_m$}}$$\n",
    "\n",
    "$$p_{x,y}^{(m+1)} = \\frac{\\text{nombre de fois où la transition de $x$ à $y$ a été utilisée sous $\\lambda_m$}}{\\text{nombre de transitions effectuées à partir de $x$ sous $\\lambda_m$}}$$\n",
    "\n",
    "$$b_{x,v}^{(m+1)} = \\frac{\\text{nombre de fois où le modèle s’est trouvé dans l’état $x$ en observant $v$ sous $\\lambda_m$}}{\\text{nombre de fois où le modèle s’est trouvé dans l’état $x$ sous $\\lambda_m$}}$$\n",
    "\n",
    "### 3.3.2 Formules de réestimation\n",
    "\n",
    "Pour déterminer les formules de réestimation, et donc mettre en oeuvre l'algorithme de Baum-Welch, nous avons besoin des coefficients suivants :\n",
    "\n",
    "<div class=\"alert alert-danger\"> <b> Définition 3.3 </b> $$\\forall i\\in [\\![0,n-1]\\!],\\forall x,y \\in E, \\ \\xi_i(x,y) = \\mathbb{P}_\\lambda(X_i = x,X_{i+1} = y|O_0^n = v_0^n) = \\frac{\\mathbb{P}_\\lambda(X_i = x,X_{i+1} = y, O_0^n = v_0^n)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}$$</div>\n",
    "\n",
    "$\\xi_i(x,y)$ représente la probabilité, étant donnée la séquence d'observations, que le modèle caché soit dans l'état $x$ à l'instant $i$ et qu'il soit dans l'état $y$ à l'instant $i+1$.\n",
    "\n",
    "<div class=\"alert alert-danger\"> <b> Définition 3.4 </b> $$\\forall i \\in [\\![0,n]\\!], \\forall x\\in E, \\ \\gamma_i(x) = \\mathbb{P}_\\lambda(X_i = x|O_0^n = v_0^n) = \\frac{\\mathbb{P}_\\lambda(X_i = x, O_0^n = v_0^n)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}$$</div>\n",
    "\n",
    "$\\gamma_i(x)$ représente la probabilité, étant donnée la séquence d'observations, que le modèle caché soit dans l'état $x$ à l'instant $i$. \n",
    "\n",
    "Pour calculer efficacements ces coefficients au cours de l'algorithme, nous allons utiliser les coefficients de forward (déjà définis dans la partie 3.1) et les coefficients de backward, définis par :\n",
    "\n",
    "<div class=\"alert alert-danger\"> <b> Définition 3.5 [Coefficient de backward] </b>\n",
    "$$\\forall x\\in E, \\ \\left\\{\n",
    "    \\begin{array}{l}\n",
    "        \\forall i \\in [\\![0,n-1]\\!], \\ \\beta_i(x) = \\mathbb{P}_\\lambda(O_{i+1}^n = v_{i+1}^n | X_i = x) \\\\\n",
    "        \\beta_n(x) = 1 \n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Proposition 3.3 </b>: Les coefficients $\\beta_i(x)$ vérifient les relations : \n",
    "    \n",
    "$$\\left\\{\n",
    "    \\begin{array}{l}\n",
    "        \\mathbb{P}_\\lambda(O_0^n = v_0^n) = \\sum_{x\\in E} \\pi_0(x) b_{xv_0} \\beta_0(x) \\ \\ \\ \\text{(i)}\\\\\n",
    "        \\forall i \\in [\\![0,n-1]\\!], \\forall x \\in E, \\beta_{i}(x) = \\sum_{y\\in E} \\beta_{i+1}(y) p_{xy} b_{yv_{i+1}} \\ \\ \\ \\text{(ii)}\n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "</div> \n",
    "\n",
    "Démonstration de la proposition 3.3 :  \n",
    "(i) \\begin{align}\n",
    "\\mathbb{P}_\\lambda(O_0^n = v_0^n) &= \\mathbb{P}_\\lambda(O_1^n = v_1^n, O_0 = v_0)\\\\\n",
    "&= \\sum_{x\\in E} \\mathbb{P}_\\lambda(O_1^n = v_1^n, O_0 = v_0|X_0 = x)\\mathbb{P}_\\lambda(X_0 = x)\\\\\n",
    "&= \\sum_{x\\in E} \\mathbb{P}_\\lambda(O_1^n = v_1^n | X_0 = x) \\mathbb{P}_\\lambda(O_0 = v_0 | X_0 = x) \\mathbb{P}_\\lambda(X_0 = x) \\\\\n",
    "&= \\sum_{x\\in E} \\pi_0(x) b_{xv_0} \\beta_0(x)\n",
    "\\end{align}\n",
    "\n",
    "(ii) Soit $i \\in [\\![0,n-2]\\!]$ et $x \\in E$. On a : \n",
    "\\begin{align}\n",
    "\\beta_i(x) &=  \\mathbb{P}_\\lambda(O_{i+1}^n = v_{i+1}^n | X_i = x) \\\\\n",
    "&= \\mathbb{P}_\\lambda(O_{i+2}^n = v_{i+2}^n, O_{i+1} = v_{i+1} | X_i = x) \\\\\n",
    "&= \\sum_{y \\in E} \\mathbb{P}_\\lambda(O_{i+2}^n = v_{i+2}^n, O_{i+1} = v_{i+1}, X_{i+1} = y | X_i = x) \\\\\n",
    "&= \\sum_{y \\in E} \\mathbb{P}_\\lambda(O_{i+2}^n = v_{i+2}^n, O_{i+1} = v_{i+1} | X_{i+1} = y, X_i = x) \\mathbb{P}_\\lambda(X_{i+1} = y | X_i = x) \\\\\n",
    "&= \\sum_{y \\in E} \\mathbb{P}_\\lambda(O_{i+2}^n = v_{i+2}^n, O_{i+1} = v_{i+1} | X_{i+1} = y) \\mathbb{P}_\\lambda(X_{i+1} = y | X_i = x) \\\\\n",
    "&= \\sum_{y \\in E} \\mathbb{P}_\\lambda(O_{i+2}^n = v_{i+2}^n | X_{i+1} = y) \\mathbb{P}_\\lambda(O_{i+1} = v_{i+1} | X_{i+1} = y) \\mathbb{P}_\\lambda(X_{i+1} = y | X_i = x) \\\\\n",
    "&= \\sum_{y \\in E} \\beta_{i+1}(y) b_{yv_{i+1}} p_{xy} \\\\\n",
    "\\end{align}\n",
    "\n",
    "On vérifie également de manière immédiate que l'égalité est vraie pour $i = n-1$.\n",
    "\n",
    "$\\beta_i(x)$ s'agit de la probabilité d'observer la fin de la séquence d'observation (à partir de $i+1$) sachant que la suite est dans l'état $x$ à l'instant $i$. Les coefficients de backward peuvent être vus comme la deuxième partie des coefficients de forward. En effet, $\\alpha_i(x)$ représente la probabilité d'arriver en $x$ à l'instant $i$ en suivant la séquence d'observations, tandis que $\\beta_i(x)$ représente la probabilité de suivre la fin de la séquence sachant qu'on est en $x$ à l'instant $i$. En combinant les deux coefficients, nous obetenons à peu de choses près la probabilité d'être en $x$ à l'instant $i$.\n",
    "\n",
    "<img src=\"Images/Backward.png\" width=\"600px\"></img>\n",
    "\n",
    "De la même manière, il existe un lien entre les coefficients $\\alpha$, $\\beta$ et $\\xi$. En effet, comme on peut le voir sur l'image ci-dessous, avec $\\alpha_i(x)$, $\\beta_{i+1}(y)$ et les paramètres de transition et d'émission, on a les probabilités d'arriver en $x$ à l'instant $i$ suivant la séquence d'observations, d'observer la fin de la séquence en partant de $y$ à l'instant $i+1$ ainsi que la probabilité de passer de $x$ à $y$ et d'observer $v_{i+1}$. Combinant tous ces paramètres, nous pouvonss obtenir à peut de choses près $\\xi_i(x,y)$.\n",
    "<img src=\"Images/xi.png\" width=\"600px\"></img>\n",
    "\n",
    "Traduisons ces intuitions de manière mathématique. À partir des coefficients de forward et backward, nous sommes capable de calculer les coefficients $\\xi$ et $\\gamma$.\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b> Proposition 3.4</b> : $$\\forall i \\in [\\![0,n-1]\\!], \\forall x,y \\in E, \\ \\xi_i(x,y) = \\frac{\\alpha_i(x)p_{xy}b_{yv_{i+1}}\\beta_{i+1}(y)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}$$</div>\n",
    "\n",
    "Démonstration de la proposition 3.4 :  \n",
    "Soit $i \\in [\\![0,n-1]\\!]$ et $x,y \\in E$. On a :\n",
    "\\begin{align}\n",
    "\\xi_i(x,y) &= \\frac{\\mathbb{P}_\\lambda(X_i = x,X_{i+1} = y, O_0^n = v_0^n)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\\\\n",
    "&= \\frac{\\mathbb{P}_\\lambda(X_i = x,X_{i+1} = y, O_0^{i} = v_0^{i}, O_{i+1}^{n} = v_{i+1}^{n})}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}\\\\\n",
    "&= \\frac{\\mathbb{P}_\\lambda(X_i = x, O_0^{i} = v_0^{i}) \\mathbb{P}(X_{i+1} = y, O_{i+1}^{n} = v_{i+1}^{n} | X_i = x, O_0^{i} = v_0^{i})}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\\\\n",
    "&= \\frac{\\alpha_i(x) p_{xy} \\mathbb{P}(O_{i+1}^{n} = v_{i+1}^{n} | X_{i+1} = y, X_i = x) }{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\\\\n",
    "&= \\frac{\\alpha_i(x) p_{xy} b_{yv_{i+1}}\\beta_{i+1}(y)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\ \\ \\ \\text{en reprenant un calcul déjà effectué dans la démo de la propriété 3.3}\n",
    "\\end{align}\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b> Proposition 3.5</b> : $$\\forall i \\in [\\![0,n]\\!], \\forall x \\in E, \\ \\gamma_i(x) = \\frac{\\alpha_i(x)\\beta_i(x)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}$$</div>\n",
    "\n",
    "Démonstration de la proposition 3.5 :  \n",
    "Soit $i \\in [\\![0,n]\\!]$ et $x \\in E$. On a :\n",
    "\\begin{align}\n",
    "\\gamma_i(x) &= \\mathbb{P}_\\lambda(X_i = x|O_0^n = v_0^n)\\\\\n",
    "&= \\sum_{y \\in E} \\mathbb{P}_\\lambda(X_i = x, X_{i+1} = y|O_0^n = v_0^n)\\\\\n",
    "&= \\sum_{y \\in E} \\xi_i(x,y)\\\\\n",
    "&= \\sum_{y \\in E} \\frac{\\alpha_i(x)p_{xy}b_{yv_{i+1}}\\beta_{i+1}(y)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\\\\n",
    "&= \\frac{\\alpha_i(x)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\sum_{y \\in E} p_{xy}b_{yv_{i+1}}\\beta_{i+1}(y) \\\\\n",
    "&= \\frac{\\alpha_i(x)\\beta_i(x)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)}\n",
    "\\end{align}\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b> Théorème 3.6 [Formules de réestimation] </b> : On a les formules de réestimation suivantes :  \n",
    " $$\\left\\{\n",
    "    \\begin{array}{l}\n",
    "        \\pi(x) = \\gamma_0(x) \\\\\n",
    "        p_{xy} = \\frac{\\sum_{i=0}^{n-1}\\xi_i(x,y)}{\\sum_{i=0}^{n-1}\\gamma_i(x)}\\\\\n",
    "        b_{xv} = \\frac{\\sum\\limits_{i=0 \\\\ tq \\ v_i = v}^n\\gamma_i(x)}{\\sum_{i=0}^{n}\\gamma_i(x)}\n",
    "    \\end{array}\n",
    "\\right.$$</div>\n",
    "\n",
    "La démonstration de ces formules de réestimation est assez longue. Néanmoins, les grandes idées sont expliquées de manière assez claires [ici](https://ssli.ee.washington.edu/people/duh/projects/EM+MMIE.pdf) et [ici](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.1457&rep=rep1&type=pdf). L'idée est de maximiser la fonction auxiliaire de Baum par rapport aux nouveaux paramètres afin de trouver un nouveau $\\lambda_{m+1}$ qui nous assure d'améliorer la probabilité $\\mathbb{P}_{\\lambda_{m+1}}(O_0^n = v_0^n)$. En résolvant ce problème d'optimisation, on trouve précisément les formules de réestimation du théorème.\n",
    "\n",
    "### 3.3.3 Algorithme de Baum-Welch\n",
    "\n",
    "Nous avons maintenant toutes les clés en main pour implémenter l'algorithme. Le pseudo-code est donné par :\n",
    "\n",
    "<img src=\"Images/PseudoCodeBaumWelch.png\" width=\"600px\"></img>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward(pi_0,P,B,obs_seq):\n",
    "    \"\"\"Retourne une matrice contenant les coefficients de forward\n",
    "    pi_0 : conditions initiales de la suite cachée\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\n",
    "    obs_seq : liste d'observations\n",
    "    \"\"\"\n",
    "    N_etat = P.shape[0]\n",
    "    n_max = len(obs_seq) - 1\n",
    "    \n",
    "    forward = np.zeros((N_etat,n_max+1))\n",
    "    \n",
    "    forward[:,0] = pi_0*B[:,obs_seq[0]]\n",
    "    for i in range(1,n_max+1):\n",
    "        for x in range(N_etat):\n",
    "            prod = forward[:,i-1] * P[:,x] * B[x,obs_seq[i]]\n",
    "            forward[x,i] = np.sum(prod)\n",
    "            \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_backward(pi_0,P,B,obs_seq):\n",
    "    \"\"\"Retourne une matrice contenant les coefficients de backward\n",
    "    pi_0 : conditions initiales de la suite cachée\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\n",
    "    obs_seq : liste d'observations\n",
    "    \"\"\"\n",
    "    N_etat = P.shape[0]\n",
    "    n_max = len(obs_seq) - 1\n",
    "\n",
    "    backward = np.zeros((N_etat,n_max+1))\n",
    "    \n",
    "    backward[:,n_max] = 1\n",
    "    for i in range(n_max-1,-1,-1):\n",
    "        for x in range(N):\n",
    "            prod = backward[:,i+1] * P[x,:] * B[:,obs_seq[i+1]]\n",
    "            backward[x,i] = np.sum(prod)\n",
    "            \n",
    "    return backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_algorithm(pi_0,P,B,obs_seq,iter_max = 15):\n",
    "    \"\"\"Retourne les paramètres optimaux maximisant la probabilité d'observer la séquence seq_obs\n",
    "    pi_0 : pi_0 initial\n",
    "    P : matrice de transition initiale\n",
    "    B : matrice d'émission initiale\n",
    "    obs_seq : liste d'observations\n",
    "    iter_max : entier naturel - nombre d'itérations de l'algorithme\"\"\"\n",
    "    \n",
    "    current_pi = np.copy(pi_0)\n",
    "    current_P = np.copy(P)\n",
    "    current_B = np.copy(B)\n",
    "    \n",
    "    N = P.shape[0] #Taille de l'espace d'état\n",
    "    V = B.shape[1] #Taille du vocabulaire\n",
    "    n = len(obs_seq) - 1 #instant final de la séquence d'observations\n",
    "    E = list(range(N))\n",
    "    Voc = list(range(V))\n",
    "    \n",
    "    xi = np.zeros((N,N,n))\n",
    "    gamma = np.zeros((N,n+1))\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        #Calcul des coefficients forward/backward\n",
    "        forwards = compute_forward(current_pi,current_P,current_B,obs_seq)\n",
    "        backwards = compute_backward(current_pi,current_P,current_B,obs_seq)\n",
    "                \n",
    "        #Calcul de xi et gamma\n",
    "        gamma = forwards * backwards / np.sum(forwards[:,n])\n",
    "        for x in E:\n",
    "            for y in E:\n",
    "                for i in range(n):\n",
    "                    xi[x,y,i] = forwards[x,i] * backwards[y,i+1] * current_P[x,y] * current_B[y,obs_seq[i+1]]\n",
    "        xi = xi/np.sum(forwards[:,n])\n",
    "        \n",
    "        #Réestimation des paramètres\n",
    "        current_pi = gamma[:,0]\n",
    "        for x in E:\n",
    "            for y in E:\n",
    "                current_P[x,y] = np.sum(xi[x,y,:])/np.sum(gamma[x,:-1])\n",
    "            for v in Voc:\n",
    "                current_B[x,v] = np.sum(gamma[x,:][np.where(np.array(obs_seq)==v)[0]])/np.sum(gamma[x,:])\n",
    "    \n",
    "    return current_pi,current_P,current_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation = ['Hot', 'Hot', 'Cold', 'Hot', 'Cold']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0.]),\n",
       " array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]]),\n",
       " array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,1,0,1,0]\n",
    "print(\"Observation = {}\".format([inv_vocabulaire[x] for x in sequence]))\n",
    "new_pi,new_P,new_B = baum_welch_algorithm(pi_0,P,B,sequence)\n",
    "np.round(new_pi,3),np.round(new_P,3), np.round(new_B,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec ces nouveaux paramètres, la probabilité d'observer ['Hot', 'Hot', 'Cold', 'Hot', 'Cold'] est 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec ces nouveaux paramètres, la probabilité d'observer {} est {}\".format(\n",
    "    [inv_vocabulaire[x] for x in sequence],forward_algorithm(sequence,new_pi,new_P,new_B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire quelques remarques importantes : \n",
    "* l'algorithme de Baum-Welch a une complexité en $\\mathcal{O}(nN^2)$\n",
    "* le résultat dépend très fortement du point de départ. Par exemple, si certaines valeurs de $P$ ou $B$ sont nulles au départ, elles le resteront tout au long de la procédure\n",
    "* le maximum atteint n'est qu'un maximum local et non global. C'est pourquoi le choix du point de départ est crucial et détermine le maximum local dans lequel on s'arrête\n",
    "* sous certaines conditions, l'algorithme peut même ne pas converger du tout (une division pas 0 est si vite arrivée). C'est souvent le cas lorsque l'on a aucune idée de la solution optimale\n",
    "* enfin, il est possible de généraliser cet algorithme avec plusieurs observations (de longueurs potentiellement différentes). Il est alors nécessaire de prendre en compte toutes les séquences dans la mise à jour des paramètres, comme [cet article](https://d1wqtxts1xzle7.cloudfront.net/48637127/P971225.pdf?1473241366=&response-content-disposition=inline%3B+filename%3DTraining_Hidden_Markov_Models_with_Multi.pdf&Expires=1610296521&Signature=QkpkDoQ-G06y4uBqyGBCkWgdRjszxqSVF3gRUCFlyDDr98pVJFZOwHZoA7LTwcIxJc6GLMmF0WX7Gt4TsVmMGa7YmaM65CWi7LdN8ab8TkBQyXky~h0RRf9rieamlDA4iBYrB1GVajJGDW2bpxJ6x4vM-2ySnBKVmKW4GpgFrgt59E2Fdy8Wuwk9RRq7xwpjx1SDcXVHYUlfYwhH0hOU8MXFCb0~BadK0D9-dhtHg5dFWWzyNF03682WQ5NhfV8SFg1~f6nYilhUs-V90dmHB95EPqi9KZ~AYEu4jaTK69QRLJtm4LozVDdL81C-C5ZH9Nqd5JntKJDXIvvRex1uLw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA) le décrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation = ['Hot', 'Hot', 'Cold', 'Hot', 'Cold']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.333, 0.333, 0.333]),\n",
       " array([[0.333, 0.333, 0.333],\n",
       "        [0.333, 0.333, 0.333],\n",
       "        [0.333, 0.333, 0.333]]),\n",
       " array([[0.4, 0.6],\n",
       "        [0.4, 0.6],\n",
       "        [0.4, 0.6]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algorithme de Baum-Welch avec un autre point de départ\n",
    "print(\"Observation = {}\".format([inv_vocabulaire[x] for x in sequence]))\n",
    "pi_0_test = np.array([1/3,1/3,1/3])\n",
    "P_test = np.array([[1/3,1/3,1/3],[1/3,1/3,1/3],[1/3,1/3,1/3]])\n",
    "B_test = np.array([[1/2,1/2],[1/2,1/2],[1/2,1/2]])\n",
    "new_pi,new_P,new_B = baum_welch_algorithm(pi_0_test,P_test,B_test,sequence)\n",
    "np.round(new_pi,3),np.round(new_P,3), np.round(new_B,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id=\"sec4\"></a> Cas d'application : Part-of-Speech tagging\n",
    "\n",
    "Que ce soit pour les êtres humains ou les ordinateurs, le problème d'identification de la catégorie syntaxique de chaque mot (ou *Part-of-Speech tagging*) d'une phrase a une grande importance dans le traitement du langage naturel : \n",
    "\n",
    "* pour comprendre le sens et la structure de la phrase\n",
    "* pour comprendre le lien entre les mots : un nom est souvent précédé d'un déterminant par exemple\n",
    "* pour enlever des ambiguités : un mot peut avoir plusieurs sens, qui dépend alors du contexte de la phrase\n",
    "\n",
    "Nous, les êtres humains, apprenons à identifier la catégorie syntaxique de chaque mot d'une phrase dès l'enfance afin que ce processus deviennent de plus en plus naturel jusqu'à ce qu'il soit quasi instinctif. En revanche, un ordinateur ne sait pas le faire tout seul. Il est donc nécessaire de développer un modèle mathématique capable de le faire automatiquement étant donnée une phrase. Nous allons ici construire un tel modèle à l'aide d'un **modèle de Markov caché**.  \n",
    "En pratique, le POS tagging est entre autre utilisé dans la synthèse vocale afin de déterminer la bonne prononciation d'un mot lorsqu'il en possède plusieurs selon le contexte.  \n",
    "[L'université de Standford](https://web.stanford.edu/~jurafsky/slp3/8.pdf) donne une bonne vision global de ce problème.\n",
    "\n",
    "## 4.1 Définition du modèle et stratégie\n",
    "\n",
    "### 4.1.1 Problème d'ambigüité\n",
    "\n",
    "Plus techniquement, étant donnée une phrase, le Part-of-Speech tagging consiste à assigner un label, ou un tag, à chaque mot de la phrase. Autrement dit, à partir d'une séquence $v_0,...,v_n$ de mots appartenant à un vocabulaire $\\mathcal{V}$, il existe une séquence de tags $x_0,...,x_n$ associée (à valeurs dans une liste de tag $E$), où le tag $x_i$ correspond au mot $v_i$.\n",
    "\n",
    "<img src=\"Images/POSTagger.png\" width=\"600px\"></img>\n",
    "\n",
    "À chaque phrase, il existe une et une seule séquence de tag associée : il s'agit donc d'un processus non ambigu. En revanche, les mots sont ambigus : un mot peut avoir plusieurs significations et donc plusieurs tags possibles qui sera alors déterminé par le sens de la phrase. En plus d'introduire une notion de temporalité, le choix d'un modèle de Markov caché semble pertinent puisque nous disposons seulement d'une séquence de mots (la phrase), les observations, et que la suite des tags que l'on cherche à déterminer nous est cachée.  \n",
    "\n",
    "Le problème, comme [Standford](https://web.stanford.edu/~jurafsky/slp3/8.pdf) le démontre, c'est que bien que peu de mots soient ambigus (ie possèdent plusieurs tags), ils sont très fréquemment utilisés dans le langage. Il existe une multitude d'exemples dans toutes les langues : \n",
    "* en français : *est* le verbe et *est* la localisation géographique\n",
    "* en anglais : *spring* la saison et *to spring* le verbe jaillir\n",
    "\n",
    "Le modèle construit devra alors être capable de saisir le sens de la phrase afin de résoudre ces ambigüités. \n",
    "\n",
    "### 4.1.2 Modèle de Markov caché\n",
    "\n",
    "Pour résoudre ce problème, nous allons utiliser un modèle de Markov caché. Conformément aux notations utilisées dans les trois premières parties, on note : \n",
    "\n",
    "* $E$ **l'espace d'états** : l'ensemble des tags possibles, ou encore l'ensemble des catégories syntaxiques considérées\n",
    "* $\\mathcal{V}$ **le vocabulaire** : l'ensemble des mots que le modèle connaîtra\n",
    "\n",
    "Ce choix implique que l'on effectue les hypothèses markoviennes suivantes : \n",
    "\n",
    "* **le tag à l'instant $i+1$ ne dépend que du tag à l'instant $i$**, ce qui permet de prendre en compte dans le modèle la temporalité propre au traitement du langage naturel\n",
    "* **le mot observé à l'instant $i$ ne dépend que du tag à cet instant**\n",
    "* toutes les probabilités ne dépendent pas du temps, autrement dit le modèle est supposé **homogène en temps** et **stationnaire**\n",
    "\n",
    "Pour pleinement déterminer le modèle, il faut définir ses paramètres : la condition initiale $\\pi_0$, la matrice de transition $P$ et la matrice d'émission $B$. C'est ici qu'intervient le data set. Étant donné un data set adapté contenant un certain nombre de phrases, on va alors poser : \n",
    "\n",
    "$$\\forall x \\in E, \\ \\pi_0(x) = \\frac{\\text{nombre de phrases où $x$ est le premier tag}}{\\text{nombre total de phrases}}$$\n",
    "\n",
    "$$\\forall x,y \\in E, \\ p_{xy} = \\frac{\\text{nombre de fois où la transition $x$ à $y$ a été effectuée}}{\\text{nombre de transitions à partir de $x$}} $$\n",
    "\n",
    "$$\\forall x\\in E, \\forall v \\in \\mathcal{V}, \\ b_{xv} = \\frac{\\text{nombre de fois où le modèle s’est trouvé dans l’état $x$ en observant $v$}}{\\text{nombre de fois où le modèle s’est trouvé dans l’état $x$ }} $$\n",
    "\n",
    "### 4.1.3 Stratégie\n",
    "\n",
    "Nous venons de définir le modèle de Markov caché $\\lambda = (\\pi_0,P,B)$. Notre but est alors de déterminer, étant donnée une phrase $x_0^n \\in \\mathcal{V}^{n+1}$, la séquence de tags associée la plus probable. Autrement dit, on va chercher la séquence $x_0^n \\in E^{n+1}$ qui maximise $\\mathbb{P}_\\lambda(X_0^n = x_0^n | O_0^n = v_0^n)$.  \n",
    "Or on a : \n",
    "\\begin{align}\n",
    "\\underset{x_0^n\\in E^{n+1}}{\\text{argmax}} \\ \\mathbb{P}_\\lambda(X_0^n = x_0^n | O_0^n = v_0^n) &= \\underset{x_0^n\\in E^{n+1}}{\\text{argmax}} \\ \\frac{\\mathbb{P}_\\lambda(X_0^n = x_0^n, O_0^n = v_0^n)}{\\mathbb{P}_\\lambda(O_0^n = v_0^n)} \\\\\n",
    "&= \\underset{x_0^n\\in E^{n+1}}{\\text{argmax}} \\ \\mathbb{P}_\\lambda(X_0^n = x_0^n, O_0^n = v_0^n) \\hspace{1cm} \\text{car $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$ est une constante ici}\n",
    "\\end{align}\n",
    "\n",
    "Finalement, étant donnée une phrase $x_0^n \\in \\mathcal{V}^{n+1}$, trouver sa suite de tags associée avec un modèle de Markov caché revient à résoudre le problème d'optimsation $\\underset{x_0^n\\in E^{n+1}}{\\text{argmax}} \\ \\mathbb{P}_\\lambda(X_0^n = x_0^n, O_0^n = v_0^n)$, ce que l'on sait faire efficacement grâce à **l'algorithme de Viterbi**.\n",
    "\n",
    "Le modèle de Part-of-Speech tagging va donc s'appuyer sur l'algorithme de Viterbi.\n",
    "\n",
    "## 4.2 Chargement et formatage du Data set\n",
    "\n",
    "### 4.2.1 Structure du fichier texte\n",
    "\n",
    "Nous disposons d'un data set dans le fichier *brown-universal.txt* qui fait partie du [Brown corpus](https://en.wikipedia.org/wiki/Brown_Corpus) et qui a déjà été formaté afin qu'il contienne les associations *mot/tags*.  \n",
    "Dans le fichier, chaque phrase commence par une référence unique sur la première ligne. Ensuite, sur chacune des lignes suivantes, chaque pair *mot/tag* est séparée par une tabulation. Enfin, les phrases sont séparées par un saut de ligne.  \n",
    "Le fichier est alors présenté sous la forme : \n",
    "\n",
    "    b100-6250\n",
    "    My\tDET\n",
    "    future\tADJ\n",
    "    plans\tNOUN\n",
    "    are\tVERB\n",
    "    to\tPRT\n",
    "    become\tVERB\n",
    "    a\tDET\n",
    "    language\tNOUN\n",
    "    teacher\tNOUN\n",
    "    .\t.\n",
    "\n",
    "    b100-39560\n",
    "    We\tPRON\n",
    "    ran\tVERB\n",
    "    east\tNOUN\n",
    "    for\tADP\n",
    "    \n",
    "Il est évidemment tout à fait possible de rajouter ses propres phrases au data set, sous réserve de respecter la structure ci-dessus.  \n",
    "\n",
    "### 4.2.2 Transformation du data set\n",
    "\n",
    "Une fois cela acquis, nous pouvons alors commencer à extraire les données afin de les rendre exploitables informatiquement. J'ai décidé d'utiliser un dictionnaire noté ```data_set```. Il se présente sous la forme : \n",
    "\n",
    "```\n",
    "data_set = {'b100-34972' : {'sentence': ['Shall', 'we', 'therefore', 'oppose', 'the', 'plan', '?', '?'],\n",
    " 'tag': ['VERB', 'PRON', 'ADV', 'VERB', 'DET', 'NOUN', '.', '.']},\n",
    " ...}\n",
    "```\n",
    "\n",
    "En d'autres termes, la clé représente la référence de la phrase et la valeur est un dictionnaire à 2 entrées (```'sentence'``` et ```'tag'```) et dont les valeurs sont des listes de chaînes de caractères.  \n",
    "\n",
    "Ensuite, nous allons définir 2 autres dictionnaires (```states``` et ```vocabulary```) contenant les correspondances respectivement *entier/tag* et *entier/mot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement et formatage du data set\n",
    "data_set = {}\n",
    "tagset = []\n",
    "vocab = []\n",
    "with open(\"brown-universal.txt\", \"r\") as filin:\n",
    "    for ligne in filin:\n",
    "        line = ligne.split('\\t')\n",
    "        if len(line) == 1:\n",
    "            if '\\n' not in line:\n",
    "                current_key = line[0][:-1]\n",
    "                data_set[current_key] = {\"sentence\" : [], \"tag\" : []}\n",
    "        else:\n",
    "            word,tag = [line[0],line[1][:-1]]\n",
    "            vocab.append(word)\n",
    "            tagset.append(tag)\n",
    "            data_set[current_key][\"sentence\"].append(word)\n",
    "            data_set[current_key][\"tag\"].append(tag)\n",
    "   \n",
    "    #Création de l'espace d'états et du vocabulaire\n",
    "tagset = list(set(tagset))\n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = sorted(tagset,key = str.lower)\n",
    "vocab = sorted(vocab,key = str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des correspondance entier/mots et entier/tag\n",
    "vocabulary = {}\n",
    "states = {}\n",
    "\n",
    "i = 0\n",
    "for word in vocab:\n",
    "    vocabulary[i] = word\n",
    "    i = i+1\n",
    "    \n",
    "i = 0\n",
    "for tag in tagset:\n",
    "    states[i] = tag\n",
    "    i = i+1\n",
    "\n",
    "inv_states = dict((tag,label) for label,tag in states.items())\n",
    "inv_vocabulary = dict((word,label) for label,word in vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.',\n",
       " 1: 'ADJ',\n",
       " 2: 'ADP',\n",
       " 3: 'ADV',\n",
       " 4: 'CONJ',\n",
       " 5: 'DET',\n",
       " 6: 'NOUN',\n",
       " 7: 'NUM',\n",
       " 8: 'PRON',\n",
       " 9: 'PRT',\n",
       " 10: 'VERB',\n",
       " 11: 'X'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'espace d'états contient 12 éléments.\n",
      "Le vocabulaire contient 56057 mots.\n"
     ]
    }
   ],
   "source": [
    "N = len(states) #Taille de l'espace d'états\n",
    "V = len(vocabulary) #Taille du vocabulaire\n",
    "print(\"L'espace d'états contient {} éléments.\".format(N))\n",
    "print(\"Le vocabulaire contient {} mots.\".format(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va diviser le data set en 2 sous ensembles : le set d'entraînement et le set de test. Nous calculerons les paramètres du modèle avec le premier et nous le testerons avec le second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des sets d'entraînement et de test\n",
    "from random import shuffle\n",
    "keys = list(data_set.keys())\n",
    "shuffle(keys)\n",
    "split_index = 4*len(keys)//5\n",
    "train_keys, test_keys = keys[:split_index], keys[split_index:]\n",
    "\n",
    "train_set = {}\n",
    "test_set = {}\n",
    "for key in train_keys:\n",
    "    train_set[key] = data_set[key]\n",
    "for key in test_keys:\n",
    "    test_set[key] = data_set[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le data set complet contient 57340 phrases.\n",
      "Le set d'entraînement contient 45872 phrases.\n",
      "Le set de test contient 11468 phrases.\n"
     ]
    }
   ],
   "source": [
    "print(\"Le data set complet contient {} phrases.\".format(len(data_set)))\n",
    "print(\"Le set d'entraînement contient {} phrases.\".format(len(train_set)))\n",
    "print(\"Le set de test contient {} phrases.\".format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulaire d'entraînement\n",
    "train_vocab = []\n",
    "for key in train_set:\n",
    "    train_vocab += train_set[key][\"sentence\"]\n",
    "train_vocab = set(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : b100-48320\n",
      "\n",
      "Words :\n",
      "\tEven Barton could not quite believe it .\n",
      "\n",
      "Corresponding tags :\n",
      "\tADV NOUN VERB ADV ADV VERB PRON .\n"
     ]
    }
   ],
   "source": [
    "#Exemple tiré du data set\n",
    "key = keys[0]\n",
    "sample = data_set[key]\n",
    "print(\"Sentence : \"+key)\n",
    "print(\"\\nWords :\")\n",
    "print(\"\\t\" + \" \".join(sample[\"sentence\"]))\n",
    "print(\"\\nCorresponding tags :\")\n",
    "print(\"\\t\" +\" \".join(sample[\"tag\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Calcul des paramètres du modèle de Markov caché\n",
    "\n",
    "De la même manière que pour un réseau de neurone, nous allons seulement utiliser le set d'entraînement afin de calculer les paramètres $\\lambda = (\\pi_0,P,B)$ du modèle de Markov cachée à l'aide des formules énoncées plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de pi_0 et de P à partir du set d'entraînement\n",
    "pi_0 = np.zeros(N)\n",
    "P = np.zeros((N,N))\n",
    "for key in train_set:\n",
    "    tag_sample = train_set[key][\"tag\"]\n",
    "    first_tag = tag_sample[0]\n",
    "    pi_0[inv_states[first_tag]] += 1\n",
    "    for tag1,tag2 in zip(tag_sample[:-1],tag_sample[1:]):\n",
    "        P[inv_states[tag1],inv_states[tag2]] += 1\n",
    "        \n",
    "pi_0 = pi_0/np.sum(pi_0)\n",
    "for i in range(P.shape[0]):\n",
    "    P[i] = P[i]/np.sum(P[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de B à partir du set d'entraînement\n",
    "B = np.zeros((N,V))\n",
    "for key in train_set:\n",
    "    sentence,tag = train_set[key][\"sentence\"], train_set[key][\"tag\"]\n",
    "    for i in range(len(sentence)):\n",
    "        B[inv_states[tag[i]],inv_vocabulary[sentence[i]]] += 1\n",
    "        \n",
    "for i in range(B.shape[0]):\n",
    "    B[i] = B[i]/np.sum(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12,), (12, 12), (12, 56057))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0.shape,P.shape,B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Prédictions et performances\n",
    "\n",
    "Nous avons désormais pleinement défini le modèle $\\lambda = (\\pi_0,P,B)$. Nous sommes prêts pour faire des prédictions et évaluer les performances du modèles sur le set de test. Nous allons calculer la précision du modèle sur le set d'entraînement via la formule :\n",
    "$$Accuracy(data\\_set) = \\frac{\\sum\\limits_{\\text{sentence $\\in$ data_set}} \\sum\\limits_{i=0}^{\\text{len}(sentence)-1} \\mathbb{1}(\\text{predicted_tag}_i = \\text{true_tag}_i)}{\\sum\\limits_{\\text{sentence $\\in$ data_set}} \\text{len}(sentence)} \\hspace{1cm} \\text{où $\\mathbb{1}$ est la fonction indicatrice}$$\n",
    "Autrement dit, il s'agit seulement du ratio de bonnes prédictions sur le nombre de prédictions réalisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_word_in_train_vocab(sequence):\n",
    "    \"\"\"Retourne True si tous les mots de la séquence sont dans le vocabulaire d'entraînement\n",
    "    sequence : liste de chaînes de caratères\"\"\"\n",
    "    for word in sequence:\n",
    "        if word not in train_vocab:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data_set,pi_0,P,B,check_word = False):\n",
    "    \"\"\"Retourne la proportion de bonnes prédictions sur un data set donné, la matrice de confusion et les références des prédictions fausses\n",
    "    data_set : dictionnaire contenant les mots et les tags\n",
    "    pi_0 : conditions initiales\n",
    "    P : matrice de transition\n",
    "    B : matrice d'émission\n",
    "    check_word : True si on vérifie que tous les mots d'une séquence appartienne au vocabulaire d'entraînement \"\"\"\n",
    "    keys = list(data_set.keys())\n",
    "    nb_pred = 0\n",
    "    true_pred = 0\n",
    "    confusion_matrix = np.zeros((N,N),dtype=int) #Matrice de confusion\n",
    "    wrong_keys = []\n",
    "    \n",
    "    for i,key in enumerate(keys):\n",
    "        sample = data_set[key]\n",
    "        \n",
    "        #On ne prend que les exemples dont tous les mots sont dans le vocabulaire d'entraînement\n",
    "        if check_word == True:\n",
    "            if all_word_in_train_vocab(sample[\"sentence\"]) == True:\n",
    "                observations = [inv_vocabulary[x] for x in sample[\"sentence\"]]\n",
    "                #Prédictions\n",
    "                predicted_tags,proba = viterbi_algorithm(observations,pi_0,P,B)\n",
    "                true_tags = [inv_states[x] for x in sample[\"tag\"]]\n",
    "                true_pred += sum(p==t for (p,t) in zip(predicted_tags,true_tags))\n",
    "                #Mise à jour de la matrice de confusion\n",
    "                for j in range(len(predicted_tags)):\n",
    "                    confusion_matrix[predicted_tags[j],true_tags[j]] +=1\n",
    "                    \n",
    "                #Clé contenant des mauvaises prédictions\n",
    "                if sum(p==t for (p,t) in zip(predicted_tags,true_tags)) != len(predicted_tags):\n",
    "                    wrong_keys.append(key)\n",
    "                \n",
    "                nb_pred += len(predicted_tags)\n",
    "                \n",
    "        else:\n",
    "            observations = [inv_vocabulary[x] for x in sample[\"sentence\"]]\n",
    "            #Prédictions\n",
    "            predicted_tags,proba = viterbi_algorithm(observations,pi_0,P,B)\n",
    "            true_tags = [inv_states[x] for x in sample[\"tag\"]]\n",
    "            true_pred += sum(p==t for (p,t) in zip(predicted_tags,true_tags))\n",
    "            #Mise à jour de la matrice de confusion\n",
    "            for j in range(len(predicted_tags)):\n",
    "                confusion_matrix[predicted_tags[j],true_tags[j]] +=1\n",
    "                \n",
    "            #Clé contenant des mauvaises prédictions\n",
    "            if (sum(p==t for (p,t) in zip(predicted_tags,true_tags)) != len(predicted_tags)) and (predicted_tags.count(0) > 10):\n",
    "                wrong_keys.append(key)\n",
    "            nb_pred += len(predicted_tags)\n",
    "            \n",
    "        if (i%1000 == 0):\n",
    "            print(\"*\",end='')\n",
    "    \n",
    "    print(\"\\nL'algorithme a effectué {} prédictions.\".format(nb_pred))\n",
    "    return true_pred/nb_pred, confusion_matrix,wrong_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "L'algorithme a effectué 232575 prédictions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7575577770611631"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc,confusion_matrix,wrong_keys = accuracy(test_set,pi_0,P,B)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons à une précision de $75\\%$. Cela veut dire que l'algorithme prédit le bon tag sur le set de test trois fois sur quatre. Intéressons nous aux erreurs, via la matrice de confusion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>29306</td>\n",
       "      <td>4820</td>\n",
       "      <td>7287</td>\n",
       "      <td>2496</td>\n",
       "      <td>2282</td>\n",
       "      <td>6044</td>\n",
       "      <td>16618</td>\n",
       "      <td>838</td>\n",
       "      <td>1611</td>\n",
       "      <td>1217</td>\n",
       "      <td>8200</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0</td>\n",
       "      <td>11384</td>\n",
       "      <td>8</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20829</td>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>355</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "      <td>329</td>\n",
       "      <td>8185</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>5354</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>20902</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37600</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>776</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>282</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4436</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>27851</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          .    ADJ    ADP   ADV  CONJ    DET   NOUN   NUM  PRON   PRT   VERB  \\\n",
       ".     29306   4820   7287  2496  2282   6044  16618   838  1611  1217   8200   \n",
       "ADJ       0  11384      8   336     0      0    292     0     0     7     72   \n",
       "ADP       0     10  20829   259     1    118      2     0    66   355     36   \n",
       "ADV       0    379    329  8185    27     26     24     0     1    30     22   \n",
       "CONJ      0      0     31    14  5354      5      0     0     0     0      0   \n",
       "DET       0      0     20    26    10  20902      6     0    46     0      0   \n",
       "NOUN      0    163      3    19     0      3  37600    13     2    19    776   \n",
       "NUM       0      0      0     0     0      1     89  1986     0     0      0   \n",
       "PRON      0      1     50     3     0    161      0     0  8303     1      0   \n",
       "PRT       0     40    282   108     0      0      6     0     0  4436      5   \n",
       "VERB      0     67     25     5     0      0    386     0     0     4  27851   \n",
       "X         1      0      0     0     0      0      3     0     0     0      0   \n",
       "\n",
       "        X  \n",
       ".     155  \n",
       "ADJ     0  \n",
       "ADP     2  \n",
       "ADV     1  \n",
       "CONJ    0  \n",
       "DET     4  \n",
       "NOUN   12  \n",
       "NUM     0  \n",
       "PRON    3  \n",
       "PRT     0  \n",
       "VERB    2  \n",
       "X      53  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix,index=tagset,columns = tagset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme se trompe beacucoup en prédisant trop souvent la première catégorie. Essayons de comprendre pourquoi avec un exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : b100-55580\n",
      "Words :\n",
      "\tRichard was a solitary student in New York and acquired , in his remoteness , a thorough if bookish knowledge of Asian lore , literature , life , politics and history .\n",
      "\n",
      "True tags :\n",
      "\tNOUN VERB DET ADJ NOUN ADP ADJ NOUN CONJ VERB . ADP DET NOUN . DET ADJ ADP ADJ NOUN ADP ADJ NOUN . NOUN . NOUN . NOUN CONJ NOUN .\n",
      "\n",
      "Predicted tags :\n",
      "\tNOUN VERB DET ADJ NOUN ADP ADJ NOUN CONJ VERB . ADP DET . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "wrong_key = wrong_keys[0]\n",
    "exemple = test_set[wrong_key]\n",
    "print(\"Sentence : \"+wrong_key)\n",
    "print(\"Words :\")\n",
    "print(\"\\t\" + \" \".join(exemple[\"sentence\"]))\n",
    "print(\"\\nTrue tags :\")\n",
    "print(\"\\t\" +\" \".join(exemple[\"tag\"]))\n",
    "print(\"\\nPredicted tags :\")\n",
    "tags = [states[y] for y in viterbi_algorithm([inv_vocabulary[x] for x in exemple[\"sentence\"]],pi_0,P,B)[0]]\n",
    "print(\"\\t\" + \" \".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mot \"remoteness\" n'est pas dans le vocabulaire d'entraînement.\n"
     ]
    }
   ],
   "source": [
    "problematic_index = 1\n",
    "#Remonté jusqu'à l'indice problématique\n",
    "while tags[-problematic_index] == '.':\n",
    "    problematic_index+=1\n",
    "\n",
    "#On retire les bonnes prédictions\n",
    "true_tags = exemple[\"tag\"]\n",
    "problematic_index -= 1\n",
    "while true_tags[-problematic_index] == '.':\n",
    "    problematic_index -= 1\n",
    "    \n",
    "#On affiche le 1er mot problématiquqe\n",
    "problematic_word = exemple['sentence'][-problematic_index]\n",
    "if problematic_word not in train_vocab:\n",
    "    print(\"Le mot \\\"{}\\\" n'est pas dans le vocabulaire d'entraînement.\".format(problematic_word))\n",
    "else:\n",
    "    print(\"\\\"{}\\\" est dans le vocabulaire entraînement.\".format(problematic_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'algorithme semble planter lorsqu'un mot présent dans une phrase n'appartient pas au vocabulaire d'entraînement. À partir d'un tel mot, il ne prédit que le tag '.', ce qui explique alors la forme de la matrice de confusion. C'est pourquoi nous allons réappliquer l'algorithme sur le set de test, mais en ne considérant que les phrases dont tous les mots appartiennent au vocabulaire d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "L'algorithme a effectué 134122 prédictions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9724504555553899"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc,confusion_matrix,wrong_keys = accuracy(test_set,pi_0,P,B,check_word=True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons alors à une précision de $97\\%$ ! En ne gardant les phrases dont tous les mots appratiennent au vocabulaire d'entraînement, on effectue tout de même plus de 130000 prédictions. L'algorithme est donc très performant.  \n",
    "Intéressons nous aux erreurs via la matrice de confusion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>17284</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0</td>\n",
       "      <td>8784</td>\n",
       "      <td>5</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15689</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>286</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>239</td>\n",
       "      <td>6343</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>4182</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>15539</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29122</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>635</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>179</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3531</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          .   ADJ    ADP   ADV  CONJ    DET   NOUN   NUM  PRON   PRT   VERB  \\\n",
       ".     17284     4      4     1     1      3      5     0     0     2      7   \n",
       "ADJ       0  8784      5   263     0      0    232     0     0     2     56   \n",
       "ADP       0     5  15689   208     0     93      1     0    45   286     26   \n",
       "ADV       0   289    239  6343    19     13     18     0     1    26     20   \n",
       "CONJ      0     0     23    11  4182      5      0     0     0     0      0   \n",
       "DET       0     0     17    20     8  15539      4     0    37     0      0   \n",
       "NOUN      0   105      3    15     0      1  29122    11     2    18    635   \n",
       "NUM       0     0      0     0     0      1     67  1544     0     0      0   \n",
       "PRON      0     1     34     2     0    115      0     0  6583     1      0   \n",
       "PRT       0    27    179    90     0      0      5     0     0  3531      4   \n",
       "VERB      0    52     16     4     0      0    300     0     0     2  21785   \n",
       "X         0     0      0     0     0      0      1     0     0     0      0   \n",
       "\n",
       "       X  \n",
       ".      0  \n",
       "ADJ    0  \n",
       "ADP    0  \n",
       "ADV    0  \n",
       "CONJ   0  \n",
       "DET    1  \n",
       "NOUN   4  \n",
       "NUM    0  \n",
       "PRON   0  \n",
       "PRT    0  \n",
       "VERB   0  \n",
       "X     41  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix,index=tagset,columns=tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : b100-14385\n",
      "Words :\n",
      "\tNor has the training been enough in relation to the need .\n",
      "\n",
      "True tags :\n",
      "\tCONJ VERB DET NOUN VERB ADJ ADP NOUN ADP DET NOUN .\n",
      "\n",
      "Predicted tags :\n",
      "\tCONJ VERB DET NOUN VERB ADV ADP NOUN ADP DET NOUN .\n"
     ]
    }
   ],
   "source": [
    "wrong_key = wrong_keys[0]\n",
    "exemple = test_set[wrong_key]\n",
    "print(\"Sentence : \"+wrong_key)\n",
    "print(\"Words :\")\n",
    "print(\"\\t\" + \" \".join(exemple[\"sentence\"]))\n",
    "print(\"\\nTrue tags :\")\n",
    "print(\"\\t\" +\" \".join(exemple[\"tag\"]))\n",
    "print(\"\\nPredicted tags :\")\n",
    "tags = [states[y] for y in viterbi_algorithm([inv_vocabulary[x] for x in exemple[\"sentence\"]],pi_0,P,B)[0]]\n",
    "print(\"\\t\" + \" \".join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plusieurs grands types d'erreurs : \n",
    "\n",
    "* confusion entre les noms et les verbes\n",
    "* confusion entre les adjectifs et les adverbes\n",
    "* confusion entre les adverbes et les adpositions (prépositions)\n",
    "\n",
    "Sans surprise, ce sont les catégories qui contiennent le plus d'ambigüités. Mais les performances du modèle sont tout de même très satisfaisantes pour un premier jet.\n",
    "\n",
    "Pour finir, testons l'algorithme sur une phrase qui n'est pas dans le data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'a', 'student', '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"I am a student.\"\n",
    "sample = sample[:-1] + \" .\"\n",
    "sample.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'VERB', 'DET', 'NOUN', '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags,proba = viterbi_algorithm([inv_vocabulary[x] for x in sample.split(\" \")],pi_0,P,B)\n",
    "[states[x] for x in tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous venons de constuire très rapidement un modèle très performant et très peu coûteux de Part-of-Speech tagging en utilisant un modèle de Markov caché. Il admet cependant deux inconvénients majeurs qui altèrent ses performances : \n",
    "* nous avons réalisé une hypothèse très forte qui n'est évidemment pas tout le temps vérifiée en pratique : l'hypothèse de Markov sur les tags\n",
    "* pour que le modèle fonctionne sur de nouvelles phrases, elles doivent exclusivement contenir des mots présents dans le vocabulaire d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Les modèles de Markov cachés généralisent les chaînes de Markov classiques, bien connues dans la littérature, en associant une séquence d'observations à une suite d'états cachée. Nous avons vu qu'il existe trois problèmes fondamentaux qui ont une multitude d'applications. Ils ont fait partie des tout premiers modèles utilisés en traitement du langage naturel dans les années 1960-1970, notamment en Part-of-Speech tagging avec l'algorithme de Viterbi. Dans le milieu des années 1970, ils ont été appliqués à la reconnaissance vocale en utilisant l'algorithme de Baum-Welch, ou encore en génération de texte. Cependant, la révolution de l'apprentissage profond (ou *deep learning*) et l'utilisation relativement récente de réseaux de neurones récurrents ont rendu les modèles de Markov cachés un peu obsolètes en traitement du langage naturel. En effet, comme [cet article de Stanford](https://web.stanford.edu/~jurafsky/slp3/9.pdf) l'explique très bien, à tout instant, les réseaux de neurones récurrents prennent en compte la sortie de la couche cachée à l'instant précédent (qui dépend elle même de la prédiction à l'instant encore avant si bien qu'elle dépend des prédictions depuis l'instant initial) en plus de l'entrée à l'instant courrant afin d'effectuer la prédiction. Cela permet de prendre en compte tout le début de la phrase et de passer outre l'hypothèse markovienne qui est assez forte pour la prédiction suivante.\n",
    "\n",
    "Les modèles de Markov cachés ont également été utilisés en biologie pour analyser des séquences ADN ou encore en bio-informatique. \n",
    "\n",
    "Néanmoins, il existe une limite informatique : l'imprécision de la représentation informatique des flottants. En effet, dans tous les algorithmes, nous avons souvent additionné et multiplié des probabilités (entre $[0,1]$) qui sont souvent très faibles. La multiplication succesive de nombres très petits peut, à force, provoquer une propagation d'erreurs au cours des calculs. Une solution serait de faire tous les calculs en passant au logarithme.\n",
    "\n",
    "Enfin, il existe une librairie Python nommée [pomegranate](https://pomegranate.readthedocs.io/en/latest/index.html) qui permet de construire des modèles de Markov cachés et de résoudre tous les problèmes que nous avons évoqués. Un exemple d'utilisation de cette librairie est donné dans [ce projet](https://github.com/soheil-mpg/Hidden-Markov-Model-POS).\n",
    "\n",
    "# Bibliographie\n",
    "\n",
    "[1] [Cours sur les chaînes de Markov de l'ISAE-SUPAERO](https://personnel.isae-supaero.fr/IMG/pdf/notes_de_cours.pdf)  \n",
    "[2] [Inference in Hidden Markov Models](http://people.bordeaux.inria.fr/pierre.delmoral/hmm-cappe-moulines-ryden.pdf), Olivier Cappé, Eric Moulines et Tobias Rydén  \n",
    "[3] [L’apprentissage de modèles de Markov cachés](http://www2.agroparistech.fr/ufr-info/membres/cornuejols/Teaching/Master-ISI/ISI-10/livre2-v3(ac)-ch-12.pdf)  \n",
    "[4] [An introduction to Hidden Markov Models](https://www.tcs.rwth-aachen.de/lehre/PRICS/WS2006/kohlschein.pdf), Christian Kohlschein  \n",
    "[5] [Speech and Language Processing chapter A](https://web.stanford.edu/~jurafsky/slp3/A.pdf), Daniel Jurafsky et James H. Martin  \n",
    "[6] [A tutorial on Hidden Markov models and selected applications in speech recognition](https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf), Lawrence R. Rabiner  \n",
    "[7] [First Order Hidden Markov Model, Theory and Implementation Issues](https://www.diva-portal.org/smash/get/diva2:833697/FULLTEXT01.pdf), Mikael Nilsson  \n",
    "[8] [Training Hidden Markov Models with Multiple Observations – A Combinatorial Method](https://d1wqtxts1xzle7.cloudfront.net/48637127/P971225.pdf?1473241366=&response-content-disposition=inline%3B+filename%3DTraining_Hidden_Markov_Models_with_Multi.pdf&Expires=1610296521&Signature=QkpkDoQ-G06y4uBqyGBCkWgdRjszxqSVF3gRUCFlyDDr98pVJFZOwHZoA7LTwcIxJc6GLMmF0WX7Gt4TsVmMGa7YmaM65CWi7LdN8ab8TkBQyXky~h0RRf9rieamlDA4iBYrB1GVajJGDW2bpxJ6x4vM-2ySnBKVmKW4GpgFrgt59E2Fdy8Wuwk9RRq7xwpjx1SDcXVHYUlfYwhH0hOU8MXFCb0~BadK0D9-dhtHg5dFWWzyNF03682WQ5NhfV8SFg1~f6nYilhUs-V90dmHB95EPqi9KZ~AYEu4jaTK69QRLJtm4LozVDdL81C-C5ZH9Nqd5JntKJDXIvvRex1uLw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA), Xiaolin Li, Marc Parizeau, Réjean Plamondon􏰁  \n",
    "[9] [Speech and Language Processing chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf), Daniel Jurafsky et James H. Martin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
